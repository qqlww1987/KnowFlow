{
  "info": {
    "pdf_info": [
      {
        "para_blocks": [
          {
            "bbox": [
              120,
              97,
              492,
              157
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  120,
                  97,
                  492,
                  157
                ],
                "spans": [
                  {
                    "bbox": [
                      120,
                      97,
                      492,
                      157
                    ],
                    "type": "text",
                    "content": "Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making"
                  }
                ]
              }
            ],
            "index": 0,
            "level": 1
          },
          {
            "bbox": [
              116,
              198,
              495,
              212
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  116,
                  198,
                  495,
                  212
                ],
                "spans": [
                  {
                    "bbox": [
                      116,
                      198,
                      495,
                      212
                    ],
                    "type": "text",
                    "content": "Xiaopeng Yuan* Xingjian Zhang Ke Xu Yifan Xu Lijun Yu Jindong Wang"
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              198,
              226,
              416,
              239
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  198,
                  226,
                  416,
                  239
                ],
                "spans": [
                  {
                    "bbox": [
                      198,
                      226,
                      416,
                      239
                    ],
                    "type": "text",
                    "content": "Yushun Dong Haohan Wang†"
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              283,
              266,
              328,
              280
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  283,
                  266,
                  328,
                  280
                ],
                "spans": [
                  {
                    "bbox": [
                      283,
                      266,
                      328,
                      280
                    ],
                    "type": "text",
                    "content": "Abstract"
                  }
                ]
              }
            ],
            "index": 3,
            "level": 1
          },
          {
            "bbox": [
              142,
              293,
              468,
              448
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  142,
                  293,
                  468,
                  448
                ],
                "spans": [
                  {
                    "bbox": [
                      142,
                      293,
                      468,
                      448
                    ],
                    "type": "text",
                    "content": "Large language models (LLMs) are increasingly applied to tasks that require complex reasoning. While most benchmarks focus on evaluating final reasoning outcomes, they overlook the internal processes that lead to those outcomes—such as how a model plans, revises, and makes decisions under constraints. We argue that evaluating these internal reasoning steps is essential for understanding model behavior and improving reliability in real- world applications. To make these processes observable and measurable, we propose using strategic games as a natural and effective environment. These games operate within closed, rule- based systems and provide interpretable states, limited resources, and automatic feedback. Therefore, we propose a framework to evaluate LLMs along three core process dimensions: planning, revision, and resource- constrained decision making. To support this, we introduce a set of evaluation metrics that extend beyond traditional win rates, incorporating measures such as Over- correction Risk Rate, correction success rate, improvement slope, and over- budget ratio."
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              142,
              449,
              468,
              581
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  142,
                  449,
                  468,
                  581
                ],
                "spans": [
                  {
                    "bbox": [
                      142,
                      449,
                      468,
                      581
                    ],
                    "type": "text",
                    "content": "In a set of 4320 adversarial rounds across 12 state- of- the- art models, we find that ChatGPT- o3- mini, which demonstrates strong planning capabilities, achieves the highest composite process score (74.7% win rate, 78.6% correction success, and a +0.041 improvement slope). In contrast, Qwen- Plus, despite a high Overcorrection Risk Score of 81.6%, wins only 25.6% of its matches, primarily due to excessive resource use. We also observe a negative correlation between Over- correction Risk Rate and correction success rate (Pearson "
                  },
                  {
                    "bbox": [
                      142,
                      449,
                      468,
                      581
                    ],
                    "type": "inline_equation",
                    "content": "r = - 0.51"
                  },
                  {
                    "bbox": [
                      142,
                      449,
                      468,
                      581
                    ],
                    "type": "text",
                    "content": ", "
                  },
                  {
                    "bbox": [
                      142,
                      449,
                      468,
                      581
                    ],
                    "type": "inline_equation",
                    "content": "p = 0.093"
                  },
                  {
                    "bbox": [
                      142,
                      449,
                      468,
                      581
                    ],
                    "type": "text",
                    "content": "), suggesting that more frequent corrections do not always improve outcomes. This pattern may reflect impulsive revision strategies, where premature edits reduce overall effectiveness, while more selective approaches lead to greater accuracy. We hope this work offers a new direction for LLM evaluation—focusing not just on what models decide, but on how they decide it."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              106,
              601,
              190,
              616
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  601,
                  190,
                  616
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      601,
                      190,
                      616
                    ],
                    "type": "text",
                    "content": "1 Introduction"
                  }
                ]
              }
            ],
            "index": 6,
            "level": 1
          },
          {
            "bbox": [
              106,
              628,
              504,
              682
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  628,
                  504,
                  682
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      628,
                      504,
                      682
                    ],
                    "type": "text",
                    "content": "Large language models (LLMs) are now capable of solving increasingly complex reasoning tasks [14, 34]. As their performance on traditional benchmarks improves, it has become clear that measuring outcome accuracy alone is no longer sufficient. In many real- world scenarios, the quality of an LLM's reasoning depends not only on the final answer, but also on the internal processes it uses to arrive there: how it plans, how it revises mistakes, and how it makes decisions under resource constraints."
                  }
                ]
              }
            ],
            "index": 7
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 0
      },
      {
        "para_blocks": [
          {
            "bbox": [
              106,
              72,
              506,
              138
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  72,
                  506,
                  138
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      138
                    ],
                    "type": "text",
                    "content": "We argue that understanding these reasoning processes is a necessary next step in LLM evaluation. Current benchmarks—such as GSM8K [6] or MMLU—offer single- turn questions and measure correctness in isolation. They provide limited visibility into how a model generates hypotheses, updates them in response to feedback, or adjust its strategy over time. Automatically generated questions have been proposed to avoid memorization [32], but these bring their own issues, such as variable difficulty and occasional invalidity [18, 33]."
                  }
                ]
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              106,
              144,
              505,
              209
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  144,
                  505,
                  209
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      144,
                      505,
                      209
                    ],
                    "type": "text",
                    "content": "To address this, we propose shifting the evaluation paradigm: from static, outcome- based tests toward dynamic, process- aware environments. We identify strategic games as a particularly well- suited testbed for this purpose. Games provide closed, rule- based environments with clear feedback signals, bounded resources, and interpretable decision traces. Their structure allows us to directly observe and quantify multi- step reasoning behaviors—without requiring human annotations or handcrafted evaluation rubrics."
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              106,
              214,
              505,
              270
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  214,
                  505,
                  270
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      214,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": "In this work, we introduce AdvGameBench, a process- based evaluation framework that embeds LLMs in interactive, resource- constrained strategy games. Rather than judging success solely by win rates, our framework traces how models form plans, revise them when needed, and operate under strict resource budgets. We define a set of core evaluation dimensions—planning, revision, and resource- constrained decision making—and propose concrete metrics that capture each of them."
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              107,
              274,
              505,
              318
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  107,
                  274,
                  505,
                  318
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      274,
                      505,
                      318
                    ],
                    "type": "text",
                    "content": "To support broad and interpretable analysis, AdvGameBench spans three classic game genres—tower defense, auto battler, and turn- based combat—each chosen to expose different cognitive and strategic demands. The framework logs full model outputs and action traces, enabling detailed inspection of decision quality, revision behavior, and adherence to constraints."
                  }
                ]
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              107,
              334,
              211,
              345
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  107,
                  334,
                  211,
                  345
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      334,
                      211,
                      345
                    ],
                    "type": "text",
                    "content": "Our key contributions are:"
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              106,
              350,
              506,
              415
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  350,
                  506,
                  415
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      350,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": "- A formalization of reasoning process dimensions: planning, revision, and resource-constrained decision making.- A game-based evaluation framework that instantiates these dimensions using closed, interpretable, and reproducible environments.- A suite of evaluation metrics that measure not only whether models succeed, but how they reason through the task."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              106,
              447,
              194,
              460
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  447,
                  194,
                  460
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      447,
                      194,
                      460
                    ],
                    "type": "text",
                    "content": "2 Related work"
                  }
                ]
              }
            ],
            "index": 6,
            "level": 1
          },
          {
            "bbox": [
              106,
              481,
              505,
              558
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  481,
                  505,
                  558
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      481,
                      505,
                      558
                    ],
                    "type": "text",
                    "content": "LLMs in Gaming Applications. LLMs have rapidly evolved and demonstrated significant capabilities across various complex tasks, including gaming scenarios[22][28][12][19][15]. Early studies mainly investigated their performance in text- based adventure games. For example, Tsai et al. [24] examined the capabilities of ChatGPT within interactive fiction. Subsequent research expanded to strategic and multi- agent scenarios. Notably, Akata et al. [1] explored repeated two- player interactions such as the Prisoner's Dilemma, highlighting the models' strengths in cooperative scenarios and coordination challenges."
                  }
                ]
              }
            ],
            "index": 7
          },
          {
            "bbox": [
              106,
              563,
              505,
              629
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  563,
                  505,
                  629
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      563,
                      505,
                      629
                    ],
                    "type": "text",
                    "content": "Recent attention has increasingly shifted toward multiplayer and complex card games. Yim et al. [31] studied Guandan, a sophisticated Chinese card game characterized by imperfect information and team cooperation. Their research demonstrated that prompting LLMs with Theory of Mind- like strategies significantly improved collaborative performance, but also revealed critical gaps in managing long- horizon states. Similarly, Hu et al. [13] proposed GameArena, a benchmark designed to evaluate fine- grained reasoning skills of LLMs through specialized interactive games."
                  }
                ]
              }
            ],
            "index": 8
          },
          {
            "bbox": [
              106,
              634,
              506,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  634,
                  506,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      634,
                      506,
                      722
                    ],
                    "type": "text",
                    "content": "Existing Benchmarks for LLM Evaluation Despite these advancements, current benchmarks rely predominantly on simplified textual or stylized environments. AppWorld [23], GTBench [9], GAMEBENCH [7], MINT [27], and AgentBench [16] illustrate established efforts focusing on puzzle, multi- turn interactions, or agent- oriented tasks. Furthermore, Yang et al. [29] provided benchmarks specifically for StarCraft II, showcasing sophisticated summarization techniques in strategic gaming contexts. Another research direction evaluates strategic reasoning using game- theoretic frameworks, demonstrating how sophisticated models like GPT- 4 [20] approximate human decisions, but often fail to achieve a true rational equilibrium in adversarial or coordination- focused scenarios [17, 10]."
                  }
                ]
              }
            ],
            "index": 9
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 1
      },
      {
        "para_blocks": [
          {
            "bbox": [
              106,
              72,
              505,
              138
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  72,
                  505,
                  138
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      72,
                      505,
                      138
                    ],
                    "type": "text",
                    "content": "Multimodal and embodied approaches have also emerged as significant subfields, exemplified by works such as Voyager in Minecraft [25] and evaluations of the use of the LLM tool [30]. However, these approaches primarily tackle open- world exploration or general- purpose tasks rather than structured competitive scenarios common in mainstream gaming genres like tower defense or auto battlers. In addition, they often require frequent API interactions or repeated prompts, raising practical cost and latency concerns [26, 5]."
                  }
                ]
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              106,
              144,
              506,
              198
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  144,
                  506,
                  198
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      144,
                      506,
                      198
                    ],
                    "type": "text",
                    "content": "In contrast to previous benchmarks that rely on tool- calling or open- ended exploration, AdvGameBench evaluates LLMs within strategic, rule- based environments where decision- making processes are directly observable. The framework eliminates external dependencies, imposes explicit budget constraints, and embeds models in turn- based adversarial settings. This design enables systematic analysis of not only final outcomes but also intermediate behaviors."
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              106,
              232,
              165,
              246
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  232,
                  165,
                  246
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      232,
                      165,
                      246
                    ],
                    "type": "text",
                    "content": "3 Method"
                  }
                ]
              }
            ],
            "index": 2,
            "level": 1
          },
          {
            "bbox": [
              107,
              268,
              274,
              280
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  268,
                  274,
                  280
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      268,
                      274,
                      280
                    ],
                    "type": "text",
                    "content": "3.1 Multi model adversarial structure"
                  }
                ]
              }
            ],
            "index": 3,
            "level": 1
          },
          {
            "bbox": [
              106,
              297,
              217,
              393
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  297,
                  217,
                  393
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      297,
                      217,
                      393
                    ],
                    "type": "text",
                    "content": "We introduce a structured adversarial framework for evaluating LLMs' process- level reasoning behaviors- specifically, how models plan, revision, and resource- constrained decision making in rule- constrained environments."
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              106,
              399,
              217,
              508
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  399,
                  217,
                  508
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      399,
                      217,
                      508
                    ],
                    "type": "text",
                    "content": "Game- based, closed- loop setting. Each evaluation match embeds two LLMs in a closed, deterministic game simulator governed by explicit rules and resource constraints. Models receive identical prompts and independently generate strategies. The simulator ex "
                  }
                ]
              },
              {
                "bbox": [
                  106,
                  509,
                  380,
                  520
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      509,
                      380,
                      520
                    ],
                    "type": "text",
                    "content": "ecutes both strategies and returns a rule- verifiable win/loss outcome."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "type": "image",
            "bbox": [
              228,
              298,
              501,
              389
            ],
            "blocks": [
              {
                "bbox": [
                  228,
                  298,
                  501,
                  389
                ],
                "lines": [
                  {
                    "bbox": [
                      228,
                      298,
                      501,
                      389
                    ],
                    "spans": [
                      {
                        "bbox": [
                          228,
                          298,
                          501,
                          389
                        ],
                        "type": "image",
                        "image_path": "f0c323ba74c82a713d330c1c21e2c7df967f2187eb1f6d15fcc593a3922a0309.jpg"
                      }
                    ]
                  }
                ],
                "index": 6,
                "type": "image_body"
              },
              {
                "bbox": [
                  222,
                  397,
                  506,
                  495
                ],
                "lines": [
                  {
                    "bbox": [
                      222,
                      397,
                      506,
                      495
                    ],
                    "spans": [
                      {
                        "bbox": [
                          222,
                          397,
                          506,
                          495
                        ],
                        "type": "text",
                        "content": "Figure 1: This figure illustrates the AdvGameBench evaluation pipeline. Three strategic game genres—tower defense, auto-battler, and turn-based combat—form the core environments for model evaluation. In each round, the model generates a strategy based on explicit rules; the simulator executes the strategy and returns an outcome; the model optionally revises its plan; and this process iterates over multiple rounds. These interactions yield behavioral trajectories from which process-level metrics are computed, including win rate, over-correction risk rate, correction success rate, and over-budget rate."
                      }
                    ]
                  }
                ],
                "index": 7,
                "type": "image_caption"
              }
            ],
            "index": 6
          },
          {
            "bbox": [
              106,
              509,
              380,
              520
            ],
            "type": "text",
            "lines": [],
            "index": 8,
            "lines_deleted": true
          },
          {
            "bbox": [
              106,
              525,
              506,
              568
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  525,
                  506,
                  568
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      525,
                      506,
                      568
                    ],
                    "type": "text",
                    "content": "Role alternation across diverse games. We construct three adversarial games—tower defense, auto- battler, and turn- based combat—each targeting a distinct reasoning capability. In every round, models alternate between attacker and defender roles, exposing both offensive and defensive strategy formation."
                  }
                ]
              }
            ],
            "index": 9
          },
          {
            "bbox": [
              106,
              574,
              504,
              607
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  574,
                  504,
                  607
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      574,
                      504,
                      607
                    ],
                    "type": "text",
                    "content": "Feedback- driven revision. After each round, models receive outcome- based feedback. They may optionally revise their strategy. These revision sequences are logged and scored using process- aware metrics including correction success rate, over- correction risk, and improvement slope."
                  }
                ]
              }
            ],
            "index": 10
          },
          {
            "bbox": [
              105,
              613,
              504,
              634
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  613,
                  504,
                  634
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      613,
                      504,
                      634
                    ],
                    "type": "text",
                    "content": "Control for asymmetry. To eliminate bias, we evaluate each model pair under both move orders. This ensures symmetry and isolates model- specific behaviors from structural advantages."
                  }
                ]
              }
            ],
            "index": 11
          },
          {
            "bbox": [
              106,
              639,
              504,
              673
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  639,
                  504,
                  673
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      639,
                      504,
                      673
                    ],
                    "type": "text",
                    "content": "Adversarial matrix evaluation. The complete setup yields a dense match matrix, covering all model pairs, roles, and move orders. This enables systematic comparison of revision dynamics, constraint adherence, and planning robustness under matched conditions."
                  }
                ]
              }
            ],
            "index": 12
          },
          {
            "bbox": [
              106,
              677,
              504,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  677,
                  504,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      677,
                      504,
                      722
                    ],
                    "type": "text",
                    "content": "Original game reimplementations. All game environments are re- implemented with shifted design from popular games to avoid strategy leakage from popular games. This ensures that models cannot rely on memorized heuristics or latent familiarity with existing game patterns, preserving the objectivity of the evaluation. All these code will be public available."
                  }
                ]
              }
            ],
            "index": 13
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 2
      },
      {
        "para_blocks": [
          {
            "bbox": [
              106,
              72,
              361,
              84
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  72,
                  361,
                  84
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      72,
                      361,
                      84
                    ],
                    "type": "text",
                    "content": "3.2Game suites: Tower Defense,Auto-battler, Turn-based"
                  }
                ]
              }
            ],
            "index": 0,
            "level": 1
          },
          {
            "bbox": [
              106,
              92,
              505,
              159
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  92,
                  505,
                  159
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      92,
                      505,
                      159
                    ],
                    "type": "text",
                    "content": "To evaluate how LLMs revise and adapt across varied reasoning contexts, we design three game environments that span distinct forms of strategic complexity. Each environment imposes different constraints and interaction patterns: Tower Defense emphasizes spatial planning under sequential threats, Battle Card requires resource allocation and composition under outcome uncertainty, and Turn- based Game tests decision consistency across multi- step attribute interactions. This diversity ensures that our evaluation covers a broad spectrum of process- level reasoning behaviors."
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              106,
              163,
              506,
              208
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  163,
                  506,
                  208
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      163,
                      506,
                      208
                    ],
                    "type": "text",
                    "content": "Tower Defense Game. In this environment, models alternate between attacker and defender roles. Defenders place units on an 11- column battlefield to block attackers advancing from the right. Attackers aim to reach the left boundary, while defenders strive to destroy all attackers. Success criteria and rule violations provide clear feedback for iterative strategy refinement (see A.1)."
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              106,
              213,
              505,
              257
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  213,
                  505,
                  257
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      213,
                      505,
                      257
                    ],
                    "type": "text",
                    "content": "Battle Card Game. Models control units with distinct attributes: attackers prioritize damage, defenders emphasize protection and recovery. Units engage in automated battles, with combat sequence determined by the number of units each side possesses. The side that eliminates all opposing units first wins, offering explicit outcome- based feedback for model improvement (see A.2)."
                  }
                ]
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              106,
              262,
              505,
              317
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  262,
                  505,
                  317
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      262,
                      505,
                      317
                    ],
                    "type": "text",
                    "content": "Turn- based Attribute Game. Each side controls three characters with assigned elemental attributes (Fire, Wood, Water, Earth, Light, Dark), featuring strategic interactions based on attribute strengths and weaknesses. Characters choose three skills within a budget constraint, cycling through them in combat. Duels continue until one side remains, clearly indicating the strategic effectiveness and compliance of each model's choices (see A.3)."
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              107,
              330,
              211,
              342
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  330,
                  211,
                  342
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      330,
                      211,
                      342
                    ],
                    "type": "text",
                    "content": "3.3Evaluation metrics"
                  }
                ]
              }
            ],
            "index": 5,
            "level": 1
          },
          {
            "bbox": [
              106,
              350,
              504,
              373
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  350,
                  504,
                  373
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      350,
                      504,
                      373
                    ],
                    "type": "text",
                    "content": "To evaluate LLMs beyond raw outcomes, we define a set of metrics tracing how models revise strategies, manage constraints, and adapt over time. We categorize our metrics into three groups:"
                  }
                ]
              }
            ],
            "index": 6
          },
          {
            "bbox": [
              106,
              378,
              437,
              411
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  378,
                  437,
                  411
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      378,
                      437,
                      411
                    ],
                    "type": "text",
                    "content": "Outcome metric: measures overall performance. Revision behavior metrics: assess how models respond to failure. Constraint adherence metrics: quantify rule compliance under resource limits."
                  }
                ]
              }
            ],
            "index": 7
          },
          {
            "bbox": [
              106,
              416,
              505,
              460
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  416,
                  505,
                  460
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      416,
                      505,
                      460
                    ],
                    "type": "text",
                    "content": "Win Rate (WR). Win Rate measures the proportion of matches a model wins out of all played games, with rule violations resulting in immediate forfeiture. This metric captures the final outcome of the reasoning process and provides a baseline for comparison. It reflects how well a model integrates planning, revision, and constraint handling into an executable solution."
                  }
                ]
              }
            ],
            "index": 8
          },
          {
            "bbox": [
              106,
              464,
              505,
              531
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  464,
                  505,
                  531
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      464,
                      505,
                      531
                    ],
                    "type": "text",
                    "content": "Over- Correction Risk Rate (ORR). ORR captures how frequently a model reacts to negative feedback with a revised proposal. This metric targets a critical behavior: over- adjustment in response to failure signals. In practical settings, excessive self- editing can reduce decision stability and degrade coherence over long horizons. High ORR indicates a lack of strategic confidence or an overly reactive revision policy. The need to track this behavior is grounded in the observation that models can degrade their own solutions through unnecessary changes, even when initial plans are viable."
                  }
                ]
              }
            ],
            "index": 9
          },
          {
            "bbox": [
              106,
              536,
              505,
              591
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  536,
                  505,
                  591
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      536,
                      505,
                      591
                    ],
                    "type": "text",
                    "content": "Correction Success Rate (CSR). CSR measures how often a revision leads to an improved result- either by eliminating a rule violation or by turning a loss into a win. This metric isolates the effectiveness of the model's internal feedback loop: can it not only detect failure but also recover from it? A model that frequently edits without reliably improving demonstrates superficial adaptivity rather than meaningful self- correction."
                  }
                ]
              }
            ],
            "index": 10
          },
          {
            "bbox": [
              106,
              596,
              505,
              651
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  596,
                  505,
                  651
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      596,
                      505,
                      651
                    ],
                    "type": "text",
                    "content": "Improvement Slope "
                  },
                  {
                    "bbox": [
                      106,
                      596,
                      505,
                      651
                    ],
                    "type": "inline_equation",
                    "content": "(\\beta)"
                  },
                  {
                    "bbox": [
                      106,
                      596,
                      505,
                      651
                    ],
                    "type": "text",
                    "content": " . Improvement Slope captures whether a model improves over repeated interactions in matched environments. This measures whether the model can adapt its planning based on prior failures against a fixed opponent type. Unlike static metrics, "
                  },
                  {
                    "bbox": [
                      106,
                      596,
                      505,
                      651
                    ],
                    "type": "inline_equation",
                    "content": "\\beta"
                  },
                  {
                    "bbox": [
                      106,
                      596,
                      505,
                      651
                    ],
                    "type": "text",
                    "content": " traces whether a model learns or degrades over time. A flat or negative slope suggests overfitting or myopic adjustment; a positive slope reflects effective cumulative reasoning."
                  }
                ]
              }
            ],
            "index": 11
          },
          {
            "bbox": [
              106,
              655,
              505,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  655,
                  505,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      655,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": "Over- Budget Rate (OBR). OBR measures how often a model generates proposals that exceed explicit resource constraints. This metric directly evaluates a model's ability to integrate symbolic or numerical limits into its reasoning process. Many LLMs can optimize performance under unconstrained conditions, but OBR reveals whether they can internalize hard boundaries and behave accordingly. This behavior is essential for real- world deployment, where compliance with external rules is not optional but required for safe execution."
                  }
                ]
              }
            ],
            "index": 12
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 3
      },
      {
        "para_blocks": [
          {
            "bbox": [
              107,
              72,
              505,
              106
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  107,
                  72,
                  505,
                  106
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      72,
                      505,
                      106
                    ],
                    "type": "text",
                    "content": "Together, these metrics provide complementary views into different layers of model behavior: WR evaluates final success; ORR and CSR analyze revision dynamics; "
                  },
                  {
                    "bbox": [
                      107,
                      72,
                      505,
                      106
                    ],
                    "type": "inline_equation",
                    "content": "\\beta"
                  },
                  {
                    "bbox": [
                      107,
                      72,
                      505,
                      106
                    ],
                    "type": "text",
                    "content": " measures adaptation over time; and OBR enforces structural discipline. Further detailed metrics are discussed in Appendix B."
                  }
                ]
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              107,
              120,
              163,
              133
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  120,
                  163,
                  133
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      120,
                      163,
                      133
                    ],
                    "type": "text",
                    "content": "4 Results"
                  }
                ]
              }
            ],
            "index": 1,
            "level": 1
          },
          {
            "bbox": [
              107,
              144,
              505,
              189
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  107,
                  144,
                  505,
                  189
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      144,
                      505,
                      189
                    ],
                    "type": "text",
                    "content": "We evaluate 12 leading LLMs, including DeepSeek- R1/V3 [8], Qwen- Plus/Max [4], Claude- 3.5- Sonnet [3], ChatGPT- 4.1/4o/o3/o3- mini [20], Gemini- 2/2.5- Flash [2], and LLaMA- 3- 70B [11]. All models use the same decoding settings: temperature 0.3 and top- "
                  },
                  {
                    "bbox": [
                      107,
                      144,
                      505,
                      189
                    ],
                    "type": "inline_equation",
                    "content": "p"
                  },
                  {
                    "bbox": [
                      107,
                      144,
                      505,
                      189
                    ],
                    "type": "text",
                    "content": " 1, allowing for controlled but non- deterministic generation [21]."
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              107,
              194,
              505,
              238
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  107,
                  194,
                  505,
                  238
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      194,
                      505,
                      238
                    ],
                    "type": "text",
                    "content": "To assess robustness, each model was tested against three diverse opponents: ChatGPT- 4o, Claude3.5- Sonnet, and DeepSeek- V3. This setup avoids evaluation bias caused by shared architectures or training data. In each round, models play against all opponents in turn- based games, with the platform logging win/loss results and correction behaviors for downstream analysis."
                  }
                ]
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              106,
              250,
              320,
              262
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  250,
                  320,
                  262
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      250,
                      320,
                      262
                    ],
                    "type": "text",
                    "content": "4.1 Revision behavior: correction rate & success"
                  }
                ]
              }
            ],
            "index": 4,
            "level": 1
          },
          {
            "type": "table",
            "bbox": [
              105,
              290,
              508,
              448
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  290,
                  508,
                  448
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      290,
                      508,
                      448
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          290,
                          508,
                          448
                        ],
                        "type": "table",
                        "html": "<table><tr><td rowspan=\"2\">Model</td><td colspan=\"3\">TDG</td><td colspan=\"3\">BCG</td><td colspan=\"3\">TAG</td><td colspan=\"3\">avg</td></tr><tr><td>WR</td><td>ORR</td><td>CSR</td><td>WR</td><td>ORR</td><td>CSR</td><td>WR</td><td>ORR</td><td>CSR</td><td>WR</td><td>ORR</td><td>CSR</td></tr><tr><td>ChatGPT-4.1</td><td>45.0</td><td>85.7</td><td>40.0</td><td>52.5</td><td>69.7</td><td>65.2</td><td>57.5</td><td>82.4</td><td>67.9</td><td>51.7</td><td>79.4</td><td>56.8</td></tr><tr><td>ChatGPT-4o</td><td>65.8</td><td>81.8</td><td>55.6</td><td>60.8</td><td>44.0</td><td>63.6</td><td>59.1</td><td>82.4</td><td>46.4</td><td>58.6</td><td>70.4</td><td>52.6</td></tr><tr><td>ChatGPT-o3</td><td>75.8</td><td>41.1</td><td>57.1</td><td>76.7</td><td>50.0</td><td>88.9</td><td>70.0</td><td>30.0</td><td>66.7</td><td>74.2</td><td>40.0</td><td>73.7</td></tr><tr><td>ChatGPT-o3-mini</td><td>63.3</td><td>25.9</td><td>57.1</td><td>74.2</td><td>31.6</td><td>100.0</td><td>86.7</td><td>9.0</td><td>100.0</td><td>74.7</td><td>24.5</td><td>78.6</td></tr><tr><td>Claude-3-5-Sonnet</td><td>56.7</td><td>89.3</td><td>56.0</td><td>45.8</td><td>70.0</td><td>64.3</td><td>55.0</td><td>76.9</td><td>65.0</td><td>52.5</td><td>77.7</td><td>61.6</td></tr><tr><td>DeepSeek-R1</td><td>70.8</td><td>53.6</td><td>80.0</td><td>49.2</td><td>32.2</td><td>40.0</td><td>80.0</td><td>83.3</td><td>70.0</td><td>66.7</td><td>48.4</td><td>63.3</td></tr><tr><td>DeepSeek-V3</td><td>43.3</td><td>84.6</td><td>45.5</td><td>23.3</td><td>75.5</td><td>24.3</td><td>56.7</td><td>75.0</td><td>38.1</td><td>41.1</td><td>78.4</td><td>35.2</td></tr><tr><td>Gemini-2-Flash</td><td>15.8</td><td>90.6</td><td>10.4</td><td>49.2</td><td>65.7</td><td>60.9</td><td>38.3</td><td>67.5</td><td>28.0</td><td>34.4</td><td>76.8</td><td>27.1</td></tr><tr><td>Gemini-2-5-Flash</td><td>60.0</td><td>40.0</td><td>60.0</td><td>59.0</td><td>79.2</td><td>68.4</td><td>58.1</td><td>76.2</td><td>56.3</td><td>62.5</td><td>65.7</td><td>63.0</td></tr><tr><td>LLaMA-3-70B</td><td>33.3</td><td>90.2</td><td>29.7</td><td>42.5</td><td>76.3</td><td>51.7</td><td>65.0</td><td>69.2</td><td>66.7</td><td>46.9</td><td>80.0</td><td>45.2</td></tr><tr><td>Qwen-Max</td><td>39.2</td><td>44.7</td><td>5.8</td><td>10.8</td><td>50.0</td><td>10.3</td><td>41.7</td><td>51.3</td><td>36.9</td><td>30.5</td><td>48.9</td><td>16.9</td></tr><tr><td>Qwen-Plus</td><td>19.2</td><td>78.4</td><td>20.0</td><td>16.7</td><td>81.5</td><td>13.6</td><td>40.8</td><td>86.1</td><td>45.2</td><td>25.6</td><td>81.6</td><td>24.3</td></tr></table>",
                        "image_path": "4bb0944d0b1f57165c5c8ba9bdebd5eb19e2989bb57fb86494cccfe536ab1718.jpg"
                      }
                    ]
                  }
                ],
                "index": 6,
                "type": "table_body"
              },
              {
                "bbox": [
                  105,
                  279,
                  504,
                  289
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      279,
                      504,
                      289
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          279,
                          504,
                          289
                        ],
                        "type": "text",
                        "content": "Table 1: Benchmark Metrics (WR "
                      },
                      {
                        "bbox": [
                          105,
                          279,
                          504,
                          289
                        ],
                        "type": "inline_equation",
                        "content": "="
                      },
                      {
                        "bbox": [
                          105,
                          279,
                          504,
                          289
                        ],
                        "type": "text",
                        "content": " win rate, ORR "
                      },
                      {
                        "bbox": [
                          105,
                          279,
                          504,
                          289
                        ],
                        "type": "inline_equation",
                        "content": "="
                      },
                      {
                        "bbox": [
                          105,
                          279,
                          504,
                          289
                        ],
                        "type": "text",
                        "content": " over-correction risk, CSR "
                      },
                      {
                        "bbox": [
                          105,
                          279,
                          504,
                          289
                        ],
                        "type": "inline_equation",
                        "content": "="
                      },
                      {
                        "bbox": [
                          105,
                          279,
                          504,
                          289
                        ],
                        "type": "text",
                        "content": " correction success)"
                      }
                    ]
                  }
                ],
                "index": 5,
                "type": "table_caption"
              }
            ],
            "index": 6
          },
          {
            "bbox": [
              105,
              460,
              506,
              471
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  460,
                  506,
                  471
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      460,
                      506,
                      471
                    ],
                    "type": "text",
                    "content": "Table 1 shows the win rate, over- correction risk rate, and correction success rate for evaluated models."
                  }
                ]
              }
            ],
            "index": 7
          },
          {
            "bbox": [
              106,
              475,
              505,
              531
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  475,
                  505,
                  531
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      475,
                      505,
                      531
                    ],
                    "type": "text",
                    "content": "Win Rate. ChatGPT- o3- mini and ChatGPT- o3 achieved the highest win rates at "
                  },
                  {
                    "bbox": [
                      106,
                      475,
                      505,
                      531
                    ],
                    "type": "inline_equation",
                    "content": "74.7\\%"
                  },
                  {
                    "bbox": [
                      106,
                      475,
                      505,
                      531
                    ],
                    "type": "text",
                    "content": " and "
                  },
                  {
                    "bbox": [
                      106,
                      475,
                      505,
                      531
                    ],
                    "type": "inline_equation",
                    "content": "74.2\\%"
                  },
                  {
                    "bbox": [
                      106,
                      475,
                      505,
                      531
                    ],
                    "type": "text",
                    "content": " respectively, substantially outperforming all other models. These results suggest strong capabilities in planning and decision- making under adversarial conditions. In contrast, models such as the Qwen series and Gemini- 2- Flash exhibited significantly lower win rates, indicating weaker performance in high- pressure strategic settings."
                  }
                ]
              }
            ],
            "index": 8
          },
          {
            "bbox": [
              106,
              536,
              505,
              603
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  536,
                  505,
                  603
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      536,
                      505,
                      603
                    ],
                    "type": "text",
                    "content": "Over- correction Risk Score. This metric reflects a model's tendency to overreact to feedback through frequent revisions. Qwen- Plus, DeepSeek- V3, and Claude- 3- 5- Sonnet exhibited high Over- correction Risk Rates (ORR), suggesting an unstable decision- making process characterized by impulsive or excessive adjustments. In contrast, ChatGPT- o3- mini maintained a relatively low ORR of "
                  },
                  {
                    "bbox": [
                      106,
                      536,
                      505,
                      603
                    ],
                    "type": "inline_equation",
                    "content": "49.3\\%"
                  },
                  {
                    "bbox": [
                      106,
                      536,
                      505,
                      603
                    ],
                    "type": "text",
                    "content": " indicating a more disciplined and stable strategy that avoids unnecessary revisions unless a confident improvement is identified."
                  }
                ]
              }
            ],
            "index": 9
          },
          {
            "bbox": [
              106,
              607,
              505,
              662
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  607,
                  505,
                  662
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      607,
                      505,
                      662
                    ],
                    "type": "text",
                    "content": "Correction Success Rate. This measures the effectiveness of the attempted revisions. ChatGPT- o3- mini achieved the highest success rate at "
                  },
                  {
                    "bbox": [
                      106,
                      607,
                      505,
                      662
                    ],
                    "type": "inline_equation",
                    "content": "78.6\\%"
                  },
                  {
                    "bbox": [
                      106,
                      607,
                      505,
                      662
                    ],
                    "type": "text",
                    "content": " indicating that most of its corrections were accurate. Conversely, Qwen- Max and Qwen- Plus had success rates around "
                  },
                  {
                    "bbox": [
                      106,
                      607,
                      505,
                      662
                    ],
                    "type": "inline_equation",
                    "content": "20\\%"
                  },
                  {
                    "bbox": [
                      106,
                      607,
                      505,
                      662
                    ],
                    "type": "text",
                    "content": " despite frequent corrections, reflecting a tendency toward uninformed or premature changes- what we refer to as \"blind correction.\""
                  }
                ]
              }
            ],
            "index": 10
          },
          {
            "bbox": [
              106,
              667,
              504,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  667,
                  504,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      667,
                      504,
                      722
                    ],
                    "type": "text",
                    "content": "These findings highlight an important distinction: frequent correction behavior does not necessarily imply improved performance. High- performing models engaged in fewer revisions, but these were more targeted and successful. In contrast, models that frequently attempted corrections without sufficient understanding failed to translate effort into meaningful gains. Effective revision thus requires not just responsiveness, but discernment in identifying when and how to intervene."
                  }
                ]
              }
            ],
            "index": 11
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 4
      },
      {
        "para_blocks": [
          {
            "bbox": [
              106,
              72,
              335,
              84
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  72,
                  335,
                  84
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      72,
                      335,
                      84
                    ],
                    "type": "text",
                    "content": "4.2 Planning ability: Init-win & Improvement Slope"
                  }
                ]
              }
            ],
            "index": 0,
            "level": 1
          },
          {
            "bbox": [
              106,
              94,
              506,
              149
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  94,
                  506,
                  149
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      94,
                      506,
                      149
                    ],
                    "type": "text",
                    "content": "4.2 Planning ability: Init- win & Improvement SlopeWe evaluate planning capabilities using two complementary metrics: initial win rate (init- win), which reflects first- round performance without feedback, and improvement slope, which measures a model's ability to enhance its strategy over time. Together, they capture a model's capacity to start strong and adapt through interaction. Figure 2 shows win rate trajectories across five rounds, while Figure 3 reports improvement slopes."
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "type": "image",
            "bbox": [
              106,
              176,
              232,
              294
            ],
            "blocks": [
              {
                "bbox": [
                  106,
                  176,
                  232,
                  294
                ],
                "lines": [
                  {
                    "bbox": [
                      106,
                      176,
                      232,
                      294
                    ],
                    "spans": [
                      {
                        "bbox": [
                          106,
                          176,
                          232,
                          294
                        ],
                        "type": "image",
                        "image_path": "a7999e47cc294e3780c322532ec2bf8b71e684d66427a08eafef48595214ae67.jpg"
                      }
                    ]
                  }
                ],
                "index": 2,
                "type": "image_body"
              },
              {
                "bbox": [
                  106,
                  300,
                  239,
                  322
                ],
                "lines": [
                  {
                    "bbox": [
                      106,
                      300,
                      239,
                      322
                    ],
                    "spans": [
                      {
                        "bbox": [
                          106,
                          300,
                          239,
                          322
                        ],
                        "type": "text",
                        "content": "Figure 2: Planning performance: slope vs. initial win rate."
                      }
                    ]
                  }
                ],
                "index": 3,
                "type": "image_caption"
              }
            ],
            "index": 2
          },
          {
            "type": "image",
            "bbox": [
              246,
              175,
              501,
              293
            ],
            "blocks": [
              {
                "bbox": [
                  246,
                  175,
                  501,
                  293
                ],
                "lines": [
                  {
                    "bbox": [
                      246,
                      175,
                      501,
                      293
                    ],
                    "spans": [
                      {
                        "bbox": [
                          246,
                          175,
                          501,
                          293
                        ],
                        "type": "image",
                        "image_path": "7cd6ae2015b867248c5d3383f07f43c1f8bd93c26bf5229b09c9cfecc4185096.jpg"
                      }
                    ]
                  }
                ],
                "index": 4,
                "type": "image_body"
              },
              {
                "bbox": [
                  275,
                  311,
                  474,
                  322
                ],
                "lines": [
                  {
                    "bbox": [
                      275,
                      311,
                      474,
                      322
                    ],
                    "spans": [
                      {
                        "bbox": [
                          275,
                          311,
                          474,
                          322
                        ],
                        "type": "text",
                        "content": "Figure 3: Win-rate trajectories across five rounds."
                      }
                    ]
                  }
                ],
                "index": 5,
                "type": "image_caption"
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              106,
              338,
              506,
              427
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  338,
                  506,
                  427
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      338,
                      506,
                      427
                    ],
                    "type": "text",
                    "content": "DeepSeek- R1 achieves the highest init- win "
                  },
                  {
                    "bbox": [
                      106,
                      338,
                      506,
                      427
                    ],
                    "type": "inline_equation",
                    "content": "(75.0\\%)"
                  },
                  {
                    "bbox": [
                      106,
                      338,
                      506,
                      427
                    ],
                    "type": "text",
                    "content": " but declines over time, suggesting rigid strategy design. In contrast, ChatGPT- o3 and o3- mini start with lower win rates "
                  },
                  {
                    "bbox": [
                      106,
                      338,
                      506,
                      427
                    ],
                    "type": "inline_equation",
                    "content": "(58.3\\%)"
                  },
                  {
                    "bbox": [
                      106,
                      338,
                      506,
                      427
                    ],
                    "type": "text",
                    "content": " yet steadily improve, indicating flexible planning. Models like Gemini- 2.5- Flash and Claude- 3.5- Sonnet perform well initially but regress, likely due to static heuristics. Qwen models show little progress, pointing to weak feedback integration. Across families, only ChatGPT models consistently improve, reflecting stronger adaptation. These patterns show that robust planning requires not just strong openings, but the ability to refine strategies under pressure—a key dimension captured by process- level metrics like the improvement slope."
                  }
                ]
              }
            ],
            "index": 6
          },
          {
            "bbox": [
              107,
              444,
              294,
              454
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  444,
                  294,
                  454
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      444,
                      294,
                      454
                    ],
                    "type": "text",
                    "content": "4.3 Resource-constrained decision making"
                  }
                ]
              }
            ],
            "index": 7,
            "level": 1
          },
          {
            "bbox": [
              106,
              465,
              376,
              596
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  465,
                  376,
                  596
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "text",
                    "content": "Figure 4 reports the Over- Budget Ratio (OBR), which quantifies the proportion of turns in which a model exceeds the environment's resource constraints. While most models stay within budget in over "
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "inline_equation",
                    "content": "80\\%"
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "text",
                    "content": " of turns, the variation across models is notable. ChatGPT- o3 and ChatGPT- o3- mini maintain perfect budget adherence, never exceeding the allowed limits. In contrast, Qwen- Plus surpasses its budget in approximately half of its turns, and Qwen- Max records similarly high overuse (OBRs of 0.50 and 0.45, respectively). This pattern is strongly aligned with performance: the o3 series models not only exhibit the lowest OBRs but also achieve the highest win rates "
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "inline_equation",
                    "content": "(74.7\\%"
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "text",
                    "content": " and "
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "inline_equation",
                    "content": "74.2\\%)"
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "text",
                    "content": " , whereas the Qwen models, with the highest OBRs, perform worst in terms of win rate "
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "inline_equation",
                    "content": "(30.5\\%)"
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "text",
                    "content": " and "
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "inline_equation",
                    "content": "25.6\\%"
                  },
                  {
                    "bbox": [
                      106,
                      465,
                      376,
                      596
                    ],
                    "type": "text",
                    "content": " -"
                  }
                ]
              }
            ],
            "index": 8
          },
          {
            "bbox": [
              106,
              601,
              375,
              657
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  601,
                  375,
                  657
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      601,
                      375,
                      657
                    ],
                    "type": "text",
                    "content": "We further find a strong negative correlation between OBR and win rate (Pearson "
                  },
                  {
                    "bbox": [
                      106,
                      601,
                      375,
                      657
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{r} = - 0.95"
                  },
                  {
                    "bbox": [
                      106,
                      601,
                      375,
                      657
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{p< 0.001}"
                  },
                  {
                    "bbox": [
                      106,
                      601,
                      375,
                      657
                    ],
                    "type": "text",
                    "content": " ), indicating that effective resource management is closely tied to model success. High OBRs are often associated with reactive, post- hoc revisions- corrections made after poor initial decisions- - which typically fail to compensate for early "
                  }
                ]
              },
              {
                "bbox": [
                  106,
                  657,
                  505,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      657,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": "mistakes. Conversely, models with low OBRs demonstrate more disciplined planning and efficient execution, avoiding costly errors in the first place. These results position OBR as a meaningful process- level indicator that goes beyond outcome accuracy, revealing how well models translate abstract constraints into concrete and consistent decision- making. Strong performers not only remain within budget but also allocate their resources strategically, contributing to higher correction success and overall coherence in behavior."
                  }
                ]
              }
            ],
            "index": 9
          },
          {
            "type": "image",
            "bbox": [
              384,
              469,
              504,
              620
            ],
            "blocks": [
              {
                "bbox": [
                  384,
                  469,
                  504,
                  620
                ],
                "lines": [
                  {
                    "bbox": [
                      384,
                      469,
                      504,
                      620
                    ],
                    "spans": [
                      {
                        "bbox": [
                          384,
                          469,
                          504,
                          620
                        ],
                        "type": "image",
                        "image_path": "d6721b6d9597759f08ce12b9f9d4acddb7769325e3522440306fcf64dc62f30c.jpg"
                      }
                    ]
                  }
                ],
                "index": 10,
                "type": "image_body"
              },
              {
                "bbox": [
                  383,
                  628,
                  504,
                  649
                ],
                "lines": [
                  {
                    "bbox": [
                      383,
                      628,
                      504,
                      649
                    ],
                    "spans": [
                      {
                        "bbox": [
                          383,
                          628,
                          504,
                          649
                        ],
                        "type": "text",
                        "content": "Figure 4: Over-Budget Ratio for Each Model"
                      }
                    ]
                  }
                ],
                "index": 11,
                "type": "image_caption"
              }
            ],
            "index": 10
          },
          {
            "bbox": [
              106,
              657,
              505,
              722
            ],
            "type": "text",
            "lines": [],
            "index": 12,
            "lines_deleted": true
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 5
      },
      {
        "para_blocks": [
          {
            "bbox": [
              107,
              72,
              263,
              84
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  72,
                  263,
                  84
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      72,
                      263,
                      84
                    ],
                    "type": "text",
                    "content": "4.4 Does revising more really help?"
                  }
                ]
              }
            ],
            "index": 0,
            "level": 1
          },
          {
            "type": "image",
            "bbox": [
              105,
              97,
              504,
              191
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  97,
                  504,
                  191
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      97,
                      504,
                      191
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          97,
                          504,
                          191
                        ],
                        "type": "image",
                        "image_path": "28cd35790e04fdbe08442d3ccd1d6ac52a88e5513a9e1e24ae15930f059422a8.jpg"
                      }
                    ]
                  }
                ],
                "index": 1,
                "type": "image_body"
              },
              {
                "bbox": [
                  105,
                  197,
                  504,
                  219
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      197,
                      504,
                      219
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          197,
                          504,
                          219
                        ],
                        "type": "text",
                        "content": "Figure 5: Correlation analysis between over-correction risk rate (ORR) and four main metrics across models"
                      }
                    ]
                  }
                ],
                "index": 2,
                "type": "image_caption"
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              106,
              232,
              505,
              341
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  232,
                  505,
                  341
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "text",
                    "content": "We quantify a model's tendency to revise reactively using the over- correction risk rate (ORR)- the probability that a model submits a new strategy immediately after receiving explicit negative feedback. Figure5 presents the correlation between ORR and four process- level outcomes. We observe a moderate negative relationship between ORR and final win rate "
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "inline_equation",
                    "content": "(r = - 0.47"
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "inline_equation",
                    "content": "p = 0.13)"
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "text",
                    "content": " , suggesting that models which revise more frequently tend to achieve lower overall success. Similarly, ORR correlates negatively with improvement slope "
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "inline_equation",
                    "content": "(r = - 0.34"
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "inline_equation",
                    "content": "p = 0.28)"
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "text",
                    "content": " , indicating that frequent edits do not accelerate strategic refinement. In terms of budget use, models with higher ORR values are more likely to exceed resource constraints (OBR; "
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "inline_equation",
                    "content": "r = +0.43"
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "inline_equation",
                    "content": "p = 0.17"
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "text",
                    "content": " ), and also show lower correction success rates "
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "inline_equation",
                    "content": "(r = - 0.34"
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "inline_equation",
                    "content": "p = 0.28)"
                  },
                  {
                    "bbox": [
                      106,
                      232,
                      505,
                      341
                    ],
                    "type": "text",
                    "content": " , implying that high- frequency revision may undermine the quality of attempted corrections."
                  }
                ]
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              106,
              346,
              506,
              423
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  346,
                  506,
                  423
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      346,
                      506,
                      423
                    ],
                    "type": "text",
                    "content": "Although none of these effects reach conventional thresholds for statistical significance due to the limited sample size "
                  },
                  {
                    "bbox": [
                      106,
                      346,
                      506,
                      423
                    ],
                    "type": "inline_equation",
                    "content": "n = 12"
                  },
                  {
                    "bbox": [
                      106,
                      346,
                      506,
                      423
                    ],
                    "type": "text",
                    "content": " ), the consistency in directional trends is notable. Across all four measures, models with high over- correction risk tend to perform worse: they are less efficient, less successful overall, and less disciplined in their resource usage. In contrast, top- performing models such as CHATGPT- 03- MINT pair a low ORR with high correction success and zero budget violations. These results highlight a key insight: precision in revision- not frequency- is the hallmark of effective strategy adjustment."
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              107,
              436,
              278,
              448
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  436,
                  278,
                  448
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      436,
                      278,
                      448
                    ],
                    "type": "text",
                    "content": "4.5 Role symmetry and first-move bias"
                  }
                ]
              }
            ],
            "index": 5,
            "level": 1
          },
          {
            "type": "image",
            "bbox": [
              105,
              460,
              505,
              582
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  460,
                  505,
                  582
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      460,
                      505,
                      582
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          460,
                          505,
                          582
                        ],
                        "type": "image",
                        "image_path": "67c122380be38c1564d3be9f5c28fd798a7b65a03dc0c4f87db402bfbbafa268.jpg"
                      }
                    ]
                  }
                ],
                "index": 6,
                "type": "image_body"
              },
              {
                "bbox": [
                  151,
                  588,
                  458,
                  600
                ],
                "lines": [
                  {
                    "bbox": [
                      151,
                      588,
                      458,
                      600
                    ],
                    "spans": [
                      {
                        "bbox": [
                          151,
                          588,
                          458,
                          600
                        ],
                        "type": "text",
                        "content": "Figure 6: First-mover advantage (FMA) across three behavioral dimensions."
                      }
                    ]
                  }
                ],
                "index": 7,
                "type": "image_caption"
              }
            ],
            "index": 6
          },
          {
            "bbox": [
              105,
              612,
              506,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  612,
                  506,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      612,
                      506,
                      722
                    ],
                    "type": "text",
                    "content": "We use First- Mover Advantage (FMA) to examine how model performance differs when initiating an action versus responding to a prior move. We analyze this effect across three dimensions: win rate, over- correction risk rate, and correction success rate. As shown in Figure 6a, most models exhibit relatively minor differences in win rate between first- and second- mover roles, with FMA values generally within five percentage points. This suggests limited systematic advantage based on turn order for overall success. However, several models deviate from this trend. Gemini- 2- Flash (FMA = +13.2%) performs substantially better when acting first, while ChatGPT- 4o (FMA = - 21.7%) and Qwen- Max (FMA = - 16.7%) exhibit the opposite pattern, achieving higher win rates when playing second. These results suggest that certain models are more sensitive to the structural asymmetries introduced by move order."
                  }
                ]
              }
            ],
            "index": 8
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 6
      },
      {
        "para_blocks": [
          {
            "bbox": [
              106,
              72,
              506,
              160
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  72,
                  506,
                  160
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "text",
                    "content": "Stronger patterns emerge when examining correction behavior. In Figure 6b and Figure 6c, we observe that most models show a clear preference for initiating rather than responding. For example, ChatGPT- 4o and ChatGPT- 4.1 demonstrate significantly higher over- correction risk rates when acting first "
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{(FMA = +14.8\\%)}"
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "text",
                    "content": " and "
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "inline_equation",
                    "content": "+13.8\\%"
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "text",
                    "content": " , respectively). Similarly, first- mover performance gains are evident in correction success rates for Gemini- 2.5- Flash "
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "inline_equation",
                    "content": "(+21.2\\%)"
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "text",
                    "content": " Gemini- 2- Flash "
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "inline_equation",
                    "content": "(+12.5\\%)"
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "text",
                    "content": " ,and ChatGPT- 4.1 "
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "inline_equation",
                    "content": "(+19.9\\%)"
                  },
                  {
                    "bbox": [
                      106,
                      72,
                      506,
                      160
                    ],
                    "type": "text",
                    "content": " . These findings underscore the importance of accounting for role asymmetry in evaluation setups. Our dual- first configuration helps mitigate first- mover bias, offering a more balanced and interpretable view of model behavior under asymmetric game dynamics."
                  }
                ]
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              107,
              186,
              282,
              198
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  186,
                  282,
                  198
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      186,
                      282,
                      198
                    ],
                    "type": "text",
                    "content": "4.6 Holistic comparison via radar chart"
                  }
                ]
              }
            ],
            "index": 1,
            "level": 1
          },
          {
            "bbox": [
              106,
              212,
              297,
              342
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  212,
                  297,
                  342
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      212,
                      297,
                      342
                    ],
                    "type": "text",
                    "content": "To synthesize model performance across reasoning dimensions, we constructed a radar chart visualizing five normalized metrics: win rate (WR), correction success rate (CSR), improvement slope, 1- over- correction risk rate (ORR), and 1- over- budget rate (OBR). All metrics were scaled to a common range, with inversions applied where necessary so that higher values consistently indicate better performance. This unified view enables a comparative assessment of both outcome and process quality across models."
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "type": "image",
            "bbox": [
              304,
              212,
              501,
              335
            ],
            "blocks": [
              {
                "bbox": [
                  304,
                  212,
                  501,
                  335
                ],
                "lines": [
                  {
                    "bbox": [
                      304,
                      212,
                      501,
                      335
                    ],
                    "spans": [
                      {
                        "bbox": [
                          304,
                          212,
                          501,
                          335
                        ],
                        "type": "image",
                        "image_path": "3e1fb5c2b1e2948981fcff75ef5efc84ccdfe7fdf60fa5d0cce2ecaeb3af004a.jpg"
                      }
                    ]
                  }
                ],
                "index": 3,
                "type": "image_body"
              },
              {
                "bbox": [
                  328,
                  340,
                  481,
                  352
                ],
                "lines": [
                  {
                    "bbox": [
                      328,
                      340,
                      481,
                      352
                    ],
                    "spans": [
                      {
                        "bbox": [
                          328,
                          340,
                          481,
                          352
                        ],
                        "type": "text",
                        "content": "Figure 7: Model performance metrics"
                      }
                    ]
                  }
                ],
                "index": 4,
                "type": "image_caption"
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              106,
              347,
              506,
              447
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  347,
                  506,
                  447
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      347,
                      506,
                      447
                    ],
                    "type": "text",
                    "content": "ChatGPT- o3- and o3- mini form the largest radar areas, reflecting strong, consistent performance across all dimensions. They pair high win rates with effective corrections, stable improvement, and disciplined resource use, indicating well- integrated reasoning. In contrast, models like Qwen- Plus and Qwen- Max show sharp imbalances, marked by frequent but ineffective revisions and frequent budget violations. Gemini models perform moderately in CSR and planning but are similarly constrained by high correction risk or poor budget control. These patterns highlight that top performance requires balance across planning, revision, and constraint adherence—not just isolated strength. Larger radar areas correspond to more robust reasoning pipelines, reinforcing that process quality is essential to understanding model competence."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              106,
              472,
              362,
              484
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  472,
                  362,
                  484
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      472,
                      362,
                      484
                    ],
                    "type": "text",
                    "content": "4.7 Model-Specific Strengths and Underlying Mechanisms"
                  }
                ]
              }
            ],
            "index": 6,
            "level": 1
          },
          {
            "bbox": [
              106,
              498,
              505,
              607
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  498,
                  505,
                  607
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      498,
                      505,
                      607
                    ],
                    "type": "text",
                    "content": "Our evaluation shows that different LLMs exhibit distinct process- level strengths, often reflecting differences in architecture and alignment. Models from the ChatGPT family—especially o3 and o3- mini—achieve consistently high win rates while maintaining disciplined correction behavior and strict budget adherence. This pattern suggests a stable internal revision mechanism, likely shaped by reinforcement learning with human feedback (RLHF) and conservative fine- tuning objectives that prioritize reliability over exploration. In contrast, models such as Qwen- Plus and DeepSeek- V3 revise frequently but achieve low correction success and often exceed resource limits. These behaviors point to reactive decision- making and overly eager feedback incorporation, which can destabilize planning over time. We refer to this pattern as “over- correction,” where excessive responsiveness leads to fragmented strategies and reduced overall performance."
                  }
                ]
              }
            ],
            "index": 7
          },
          {
            "bbox": [
              106,
              612,
              505,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  612,
                  505,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      612,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": "Other models, including Claude- 3.5- Sonnet and Gemini- 2.5- Flash, show more balanced profiles across metrics. While they do not dominate any single dimension, they perform moderately well in planning, correction, and resource management. This may reflect broader instruction- tuning or multitask training that encourages general adaptability without specializing in any one skill. Taken together, these differences underscore that LLM capabilities are shaped by design trade- offs: between caution and flexibility, local reactivity and global coherence. Our process- level metrics—particularly ORR and improvement slope—help reveal these trade- offs, offering a more nuanced view of model behavior than outcome- based evaluations alone. They also provide actionable insights into how alignment strategies and decoding preferences influence long- horizon reasoning, suggesting concrete directions for model development and benchmarking."
                  }
                ]
              }
            ],
            "index": 8
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 7
      },
      {
        "para_blocks": [
          {
            "bbox": [
              106,
              70,
              179,
              84
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  70,
                  179,
                  84
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      70,
                      179,
                      84
                    ],
                    "type": "text",
                    "content": "5 Discussion"
                  }
                ]
              }
            ],
            "index": 0,
            "level": 1
          },
          {
            "bbox": [
              106,
              93,
              505,
              148
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  93,
                  505,
                  148
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      93,
                      505,
                      148
                    ],
                    "type": "text",
                    "content": "Process- rather- than- outcome evaluation. AdvGameBench purposefully shifts the evaluation lens from what an LLM answers to how it arrives there. By embedding models in three rule- bound strategy games, we can observe- and score- their behaviour along the three dimensions defined in Method section (see Method): planning (initial strategy quality and improvement slope), revision (correction rate and success), and resource- constrained decision making (budget adherence)."
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              105,
              153,
              504,
              175
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  153,
                  504,
                  175
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      153,
                      504,
                      175
                    ],
                    "type": "text",
                    "content": "Empirical studies. Our study of twelve production- scale LLMs across 4 752 adversarial rounds yields three consistent findings:"
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              105,
              180,
              506,
              293
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  180,
                  506,
                  293
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "text",
                    "content": "1. Integrated skill trumps single metrics. Models that balance the three dimensions-notably CHATGPT-O3-MINI with a "
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "inline_equation",
                    "content": "74.7\\%"
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "text",
                    "content": " win rate, "
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "inline_equation",
                    "content": "78.6\\%"
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "text",
                    "content": " correction-success rate, and positive improvement slope of "
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "inline_equation",
                    "content": "+0.0413"
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "text",
                    "content": " outperform models that excel in only one aspect. \n2. \"Spray-and-pray\" revision is counter-productive. QwEN-PLUS issues corrections in "
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "inline_equation",
                    "content": "81.6\\%"
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "text",
                    "content": " of error states yet wins only "
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "inline_equation",
                    "content": "25.6\\%"
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "text",
                    "content": " of gamer, and overspends in nearly half the turns. Across all systems, correction frequency and efficacy are negatively correlated (Pearson "
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "inline_equation",
                    "content": "r = -0.51"
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "inline_equation",
                    "content": "p = 0.093)"
                  },
                  {
                    "bbox": [
                      105,
                      180,
                      506,
                      293
                    ],
                    "type": "text",
                    "content": " , indicating that calibrated self-editing matters more than sheer persistence. \n3. Budget fidelity is a leading indicator of success. The two models that never violated resource limits (CHATGPT-O3 and CHATGPT-O3-MINI) also posted the highest win rates, whereas both Qwen variants combine the largest over-budget ratios with the poorest outcomes."
                  }
                ]
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              106,
              299,
              505,
              419
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  299,
                  505,
                  419
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      299,
                      505,
                      419
                    ],
                    "type": "text",
                    "content": "Hallucation. In our tower defense experiments, all defensive units were consistently referred to as soldiers. However, several models frequently generated the term peashooter, which was never introduced in the task instructions. A review of the interaction logs reveals that this phenomenon does not stem from a reasoning failure, but rather from prior associations learned during pretraining- - specifically, the frequent co- occurrence of \"tower defense\" and the game Plants vs. Zombies in web- scale corpora. This leads models to default to familiar terminology, even when it conflicts with the defined rules of the environment. Such behavior undermines the validity of the benchmark, effectively turning the evaluation into a test of memorized correlations rather than genuine planning or constraint adaptation. To eliminate this form of memory bias, we redesigned the game environment to neutralize lexical cues and ensure that performance reflects models' ability to engage with novel rules and dynamic constraints, rather than recalling pretraining artifacts."
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              106,
              424,
              505,
              479
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  424,
                  505,
                  479
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      424,
                      505,
                      479
                    ],
                    "type": "text",
                    "content": "Limitations. AdvGameBench currently (i) covers three turn- based genres but no real- time or cooperative play, (ii) logs unit- level actions yet does not attribute win contributions to individual decisions, and (iii) relies on synthetic opponents, which- - although diversified- - cannot fully mirror human play styles. These choices were deliberate to keep the study controlled and reproducible, but they constrain external validity."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              106,
              495,
              181,
              508
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  495,
                  181,
                  508
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      495,
                      181,
                      508
                    ],
                    "type": "text",
                    "content": "6 Conclusion"
                  }
                ]
              }
            ],
            "index": 6,
            "level": 1
          },
          {
            "bbox": [
              106,
              525,
              506,
              579
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  525,
                  506,
                  579
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      525,
                      506,
                      579
                    ],
                    "type": "text",
                    "content": "Static accuracy benchmarks have become an insufficient proxy for real- world robustness. Deployment- ready systems must also plan soundly, revise judiciously, and respect resource constraints to function effectively in practical environments. AdvGameBench meets this need by turning strategic gameplay into an open, extensible laboratory in which those process- level traits can be systematically quantified, monitored, and improved over time."
                  }
                ]
              }
            ],
            "index": 7
          },
          {
            "bbox": [
              106,
              585,
              505,
              662
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  585,
                  505,
                  662
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      585,
                      505,
                      662
                    ],
                    "type": "text",
                    "content": "By exposing the entire decision trace- from initial plan through budgeted actions and selfcorrections- the benchmark reveals failure modes that outcome- only tests often conceal. These fine- grained signals enable not only diagnostic analysis of model behavior but also principled design of training objectives that reward disciplined, context- sensitive reasoning under pressure. They also help evaluate whether models can maintain stability across repeated trials, even in adversarial or resource- limited conditions. AdvGameBench supports controlled ablations, adversarial setups, and resource perturbations, making it a flexible platform for probing model resilience."
                  }
                ]
              }
            ],
            "index": 8
          },
          {
            "bbox": [
              106,
              667,
              505,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  667,
                  505,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      667,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": "Ultimately, we see AdvGameBench as one step toward a broader shift in LLM evaluation: away from asking only \"Did the model answer correctly?\" and toward asking \"How did the model reason, adapt, and stay within bounds while answering?\" Such process- aware scrutiny is essential for building language models that are not only accurate but also reliable, accountable, and aligned with real- world deployment demands."
                  }
                ]
              }
            ],
            "index": 9
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 8
      },
      {
        "para_blocks": [
          {
            "bbox": [
              106,
              71,
              164,
              84
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  71,
                  164,
                  84
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      71,
                      164,
                      84
                    ],
                    "type": "text",
                    "content": "References"
                  }
                ]
              }
            ],
            "index": 0,
            "level": 1
          },
          {
            "bbox": [
              105,
              90,
              505,
              112
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  90,
                  505,
                  112
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      90,
                      505,
                      112
                    ],
                    "type": "text",
                    "content": "[1] Akata, E., Schulz, L., Coda- Forno, J., Oh, S. J., Bethge, M., and Schulz, E. (2023). Playing repeated games with large language models. In arXiv preprint arXiv:2305.16867v1."
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              105,
              120,
              506,
              285
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  120,
                  506,
                  285
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      120,
                      506,
                      285
                    ],
                    "type": "text",
                    "content": "[2] Anil, R., Borgeaud, S., Alayrac, J.- B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., Millican, K., Silver, D., Johnson, M., Antonoglou, I., Schrittwieser, J., Glaese, A., Chen, J., Pitler, E., Lillicrap, T., Lazaridou, A., Firat, C., Molloy, J., Isard, M., Barham, P. R., Hennigan, T., Lee, B., Viola, F., Reynolds, M., Xu, Y., Doherty, R., Collins, E., Meyer, C., Rutherford, E., Moreira, E., Ayoub, K., Goel, M., Krawczyk, J., Du, C., Chi, E., Cheng, H.- T., Ni, E., Shah, P., Kane, P., Chan, B., Faruqui, M., Severyn, A., Lin, H., Li, Y., Cheng, Y., Ittycheriah, A., Mahdieh, M., Chen, M., Sun, P., Tran, D., Bagri, S., Lakshminarayanan, B., Liu, J., Orban, A., Gira, F., Zhou, H., Song, X., Boffy, A., Ganapathy, H., Zheng, S., Choe, H., Weisz, Á., Zhu, T., Lu, Y., Gopal, S., Kahn, J., Kula, M., Pitman, J., Shah, R., Taropa, E., Al Merey, M., Baeuml, M., Chen, Z., El Shafey, L., Zhang, Y., Sercinoglu, O., Tucker, G., Piqueras, E., Krikun, M., Barr, I., Savinov, N., Danelhelka, I., Roelofs, B., White, A., Andreassen, A., von Glehn, T., Yagati, L., Kazemi, M., Gonzalez, L., Khalman, M., Sygnowski, J., Frechette, A., Smith, C., Culp, L., Prolev, L., Luan, Y., Chen, X., et al. (2025). Gemini: A Family of Highly Capable Multimodal Models. In arXiv preprint arXiv:2312.11805v5. Version v1 submitted on 19 Dec 2023, v5 (this version) revised 9 May 2025."
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              105,
              293,
              505,
              316
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  293,
                  505,
                  316
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      293,
                      505,
                      316
                    ],
                    "type": "text",
                    "content": "[3] Anthropic (2024). The claude 3 model family: Opus, Sonnet, Haiku. Technical report, Anthropic. Model Card."
                  }
                ]
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              106,
              324,
              506,
              389
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  324,
                  506,
                  389
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      324,
                      506,
                      389
                    ],
                    "type": "text",
                    "content": "[4] Bai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., Hui, B., Ji, L., Li, M., Lin, J., Lin, R., Liu, D., Liu, G., Lu, C., Lu, K., Ma, J., Men, R., Ren, X., Ren, X., Tan, C., Tan, S., Tu, J., Wang, P., Wang, S., Wang, W., Wu, S., Xu, B., Xu, J., Yang, A., Yang, H., Yang, J., Yang, S., Yao, Y., Yu, B., Yuan, H., Yuan, Z., Zhang, J., Zhang, X., Zhang, Y., Zhang, Z., Zhou, C., Zhou, J., Zhou, X., and Zhu, T. (2023). QWEN TECHNICAL REPORT. In arXiv preprint arXiv:2309.16609v1."
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              105,
              398,
              505,
              431
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  398,
                  505,
                  431
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      398,
                      505,
                      431
                    ],
                    "type": "text",
                    "content": "[5] Chiang, W.- L., Zheng, L., Sheng, Y., Angelopoulos, A. N., Li, T., Li, D., Zhu, B., Zhang, H., Jordan, M. I., Gonzalez, J. E., and Stoica, I. (2024). Chatbot arena: An open platform for evaluating LLMs by human preference. In arXiv preprint arXiv:2403.04132v1."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              106,
              439,
              506,
              483
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  439,
                  506,
                  483
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      439,
                      506,
                      483
                    ],
                    "type": "text",
                    "content": "[6] Cobb, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. (2021). Training verifiers to solve math word problems. In arXiv preprint arXiv:2110.14168v2. Version v1 submitted on 27 Oct 2021, v2 (this version) revised 18 Nov 2021."
                  }
                ]
              }
            ],
            "index": 6
          },
          {
            "bbox": [
              105,
              491,
              506,
              524
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  491,
                  506,
                  524
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      491,
                      506,
                      524
                    ],
                    "type": "text",
                    "content": "[7] Costarelli, A., Allen, M., Hauksson, R., Sodunke, G., Hariharan, S., Cheng, C., Li, W., Clymer, J., and Yadav, A. (2024). GAMEBENCH: Evaluating strategic reasoning abilities of Ilm agents. In arXiv preprint arXiv:2406.06613v2."
                  }
                ]
              }
            ],
            "index": 7
          },
          {
            "bbox": [
              105,
              532,
              504,
              555
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  532,
                  504,
                  555
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      532,
                      504,
                      555
                    ],
                    "type": "text",
                    "content": "[8] DeepSeek- AI, Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., and et al. (2024). DeepSeek- V3 Technical Report. In arXiv preprint arXiv:2412.19437."
                  }
                ]
              }
            ],
            "index": 8
          },
          {
            "bbox": [
              106,
              562,
              505,
              596
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  562,
                  505,
                  596
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      562,
                      505,
                      596
                    ],
                    "type": "text",
                    "content": "[9] Duan, J., Zhang, R., Diffenderfer, J., Kailkhura, B., Sun, L., Stengel- Eskin, E., Bansal, M., Chen, T., and Xu, K. (2024). GTBENCH: Uncovering the strategic reasoning limitations of LLMs via game- theoretic evaluations. In arXiv preprint arXiv:2402.12348v2."
                  }
                ]
              }
            ],
            "index": 9
          },
          {
            "bbox": [
              105,
              604,
              504,
              627
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  604,
                  504,
                  627
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      604,
                      504,
                      627
                    ],
                    "type": "text",
                    "content": "[10] Fan, C., Chen, J., Jin, Y., and He, H. (2023). Can large language models serve as rational players in game theory? a systematic analysis. In arXiv preprint arXiv:2312.05488v2."
                  }
                ]
              }
            ],
            "index": 10
          },
          {
            "bbox": [
              106,
              634,
              506,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  634,
                  506,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      634,
                      506,
                      722
                    ],
                    "type": "text",
                    "content": "[11] Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al- Dahle, A., Letman, A., Mathur, A., Schelten, A., Vaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra, A., Sravankumar, A., Korenev, A., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A., Gregerson, A., Spataru, A., Roziere, B., Biron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C., Bi, C., Marra, C., McConnell, C., Keller, C., Touret, C., Wu, C., Wong, C., Ferrer, C. C., Nikolaidis, C., Allonsius, D., Song, D., Pintz, D., Livshorn, D., Wyatt, D., Esiobu, D., Choudhary, D., Mahajan, D., Garcia- Olano, D., Perino, D., Hupkes, D., Lakomkin, E., AlBadawy, E., Lobanova, E., Dinan, E., Smith, E. M., Radenovic, F., Guzmán, F., Zhang, F., Synnaeve, G., Lee, G., Anderson, G. L.,"
                  }
                ]
              }
            ],
            "index": 11
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 9
      },
      {
        "para_blocks": [
          {
            "bbox": [
              105,
              72,
              506,
              138
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  72,
                  506,
                  138
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      72,
                      506,
                      138
                    ],
                    "type": "text",
                    "content": "Thattai, G., Nail, G., Mialon, G., Pang, G., Cucurell, G., Nguyen, H., Korevaar, H., Xu, H., Touvron, H., Zarov, I., Ibarra, I. A., Kloumann, I., Misra, I., Evtimov, I., Zhang, J., Copet, J., Lee, J., Geffert, J., Vranes, J., Park, J., Mahadeokar, J., Shah, J., van der Linde, J., Billock, J., Hong, J., Lee, J., Fu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton, J., Spisak, J., Park, J., Rocca, J., Johnstun, J., Saxe, J., Jia, J., et al. (2024). The Llama 3 Herd of Models. In arXiv preprint arXiv:2407.21783v3. Version v1 submitted on 31 Jul 2024, v3 (this version) revised 23 Nov 2024."
                  }
                ]
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              102,
              96,
              507,
              723
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  102,
                  96,
                  507,
                  723
                ],
                "spans": [
                  {
                    "bbox": [
                      102,
                      96,
                      507,
                      723
                    ],
                    "type": "text",
                    "content": "[12] Gupta, A. (2023). Are chatgpt and gpt- 4 good poker players? — a pre- flop analysis. In arXiv preprint arXiv:2308.12466v2. [13] Hu, L., Li, Q., Xie, A., Jiang, N., Stoica, I., Jin, H., and Zhang, H. (2025). GAMEARENA: Evaluating LLM reasoning through live computer games. In arXiv preprint arXiv:2412.06394v5. [14] Huang, J. and Chang, K. C.- C. (2023). Towards reasoning in large language models: A survey. In arXiv preprint arXiv:2212.10403v2. [15] Light, J. and et al. (2023). Avalonbench: Evaluating llms playing the game of avalon. arXiv preprint arXiv:2310.05036. [16] Liu, Y., Li, Z., Liu, P., Xie, Y., Wu, B., Zhang, Y., Wang, S., Yu, Y., Zhao, J., Lu, Z., Gao, Y., Qiao, Y., Fan, W., Ye, Y., Liang, S., and Zhao, Y. (2023). AgentBench: Evaluating LLMs as agents. In arXiv preprint arXiv:2308.03688. [17] Lore, N. and Heydari, B. (2023). Strategic behavior of large language models: Game structure vs. contextual framing. In arXiv preprint arXiv:2309.05898v1. [18] Minderer, M., Djolonga, J., Romijnders, R., Hubis, F., Zhai, X., Houlsby, N., Tran, D., and Lucic, M. (2021). Revisiting the calibration of modern neural networks. In arXiv preprint arXiv:2106.07998v2. Appeared in: 35th Conference on Neural Information Processing Systems (NeurIPS 2021). Version v1 submitted on 15 Jun 2021, v2 (this version) revised 26 Oct 2021. [19] Nannukul, N. and Wongkamjan, W. (2024). What if red can talk? dynamic dialogue generation using large language models. In arXiv preprint arXiv:2407.20382v1. [20] OpenAI (2024). GPT- 4 technical report. In arXiv preprint arXiv:2303.08774v6. [21] Renze, M. and Guven, E. (2024). The effect of sampling temperature on problem solving in large language models. In arXiv preprint arXiv:2402.05201v3. [22] Sudhakaran, S., Gonzalez- Duque, M., Freiberger, M., Glanois, C., Najarro, E., and Risi, S. (2023). MarioGPT: Open- ended Text2Level generation through large language models. In arXiv preprint arXiv:2302.05981v3. [23] Trivedi, H., Khot, T., Hartmann, M., Manku, R., Dong, V., Li, E., Gupta, S., Sabharwal, A., and Balasubramanian, N. (2024). AppWorld: A controllable world of apps and people for benchmarking interactive coding agents. In arXiv preprint arXiv:2407.18901v1. [24] Tsai, C. F., Zhou, X., Liu, S. S., Li, J., Mei, H., and Yu, M. (2023). Can large language models play text games well? current state- of- the- art and open questions. In arXiv preprint arXiv:2304.02868v1. [25] Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., and Anandkumar, A. (2023a). VOYAGER: An open- ended embodied agent with large language models. In arXiv preprint arXiv:2305.16291v2. [26] Wang, S., Long, Z., Fan, Z., Wei, Z., and Huang, X. (2024). Benchmark self- evolving: A multi- agent framework for dynamic LLM evaluation. In arXiv preprint arXiv:2402.11443v1. [27] Wang, Y., Yu, D., Dong, L., Bao, F. S., Wang, X., Wang, D., Yu, Z., Li, L., and Zhou, H. (2023b). MINT: Evaluating LLMs in multi- turn interaction with tools and language feedback. In arXiv preprint arXiv:2310.06825. [28] Xu, Y., Wang, S., Li, P., and et al. (2023). Exploring large language models for communication games: An empirical study on werewolf. arXiv preprint arXiv:2309.04658."
                  }
                ]
              }
            ],
            "index": 1
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 10
      },
      {
        "para_blocks": [
          {
            "bbox": [
              105,
              72,
              506,
              342
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  72,
                  506,
                  342
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      72,
                      506,
                      342
                    ],
                    "type": "text",
                    "content": "[29] Yang, Z., Li, H., Chen, Y., Tian, W., Ren, Y., Su, H., Zhu, J., and Sun, L. (2023a). Large language models play StarCraft II: Benchmarks and a chain of summarization approach. In arXiv preprint arXiv:2310.11432. [30] Yang, Z., Li, L., Wang, J., Lin, K., Azarnasab, E., Ahmed, F., Liu, Z., Liu, C., Zeng, M., and Wang, L. (2023b). MM- REACT: Prompting ChatGPT for multimodal reasoning and action. In arXiv preprint arXiv:2303.11381v1. [31] Yim, Y., Chan, C., Shi, T., Deng, Z., Fan, W., Zheng, T., and Song, Y. (2024). Evaluating and enhancing LLMs agent based on theory of mind in Guandan: A multiplayer cooperative game under imperfect information. In arXiv preprint arXiv:2408.02559v1. [32] Yu, X., Cheng, H., Liu, X., Roth, D., and Gao, J. (2024). ReEval: Automatic hallucination evaluation for retrieval- augmented large language models via transferable adversarial attacks. In arXiv preprint arXiv:2310.10190v2. Version v1 submitted on 19 Oct 2023, v2 (this version) revised 31 May 2024. [33] Zhang, H., Da, J., Lee, D., Robinson, V., Wu, C., Song, W., Zhao, T., Raja, P., Zhuang, C., Slack, D., Lyu, Q., Hendryx, S., Kaplan, R., Lunati, M., and Yue, S. (2024a). A careful examination of large language model performance on grade school arithmetic. In arXiv preprint arXiv:2405.00212v4. Version v1 submitted on 1 May 2024, v4 (this version) revised 22 Nov 2024. Original v1 arXiv:2405.00212. [34] Zhang, Y., Mao, S., Ge, T., Wang, X., de Wynter, A., Xia, Y., Wu, W., Song, T., Lan, M., and Wei, F. (2024b). LLM as a mastermind: A survey of strategic reasoning with large language models. In arXiv preprint arXiv:2404.01230v1."
                  }
                ]
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              107,
              361,
              178,
              376
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  361,
                  178,
                  376
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      361,
                      178,
                      376
                    ],
                    "type": "text",
                    "content": "A Appendix"
                  }
                ]
              }
            ],
            "index": 1,
            "level": 1
          },
          {
            "bbox": [
              107,
              387,
              217,
              398
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  387,
                  217,
                  398
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      387,
                      217,
                      398
                    ],
                    "type": "text",
                    "content": "A.1 Tower defense game"
                  }
                ]
              }
            ],
            "index": 2,
            "level": 1
          },
          {
            "bbox": [
              107,
              407,
              189,
              418
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  407,
                  189,
                  418
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      407,
                      189,
                      418
                    ],
                    "type": "text",
                    "content": "A.1.1 Game rules"
                  }
                ]
              }
            ],
            "index": 3,
            "level": 1
          },
          {
            "bbox": [
              105,
              423,
              506,
              577
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  423,
                  506,
                  577
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      423,
                      506,
                      577
                    ],
                    "type": "text",
                    "content": "1. Players can purchase characters and place them on the battlefield. The battlefield consists of 5 rows (corresponding to y-coordinates 0-4). The human side can place units in a designated area spanning 11 columns (corresponding to x-coordinates 0-10). \n2. Demons spawn from the right side of the battlefield (x-coordinates 11) and move left. Human units are placed on the left side of the battlefield, remain stationary, and attack approaching enemies. \n3. All units attack according to their attack interval, automatically attacking when their cooldown ends. Defending units fire bullets or activate skills to attack enemies. Invading units engage in melee attacks when they come into contact with defending units. \n4. Each grid cell can only contain one human unit at a time. Placing a new unit in an occupied cell is not allowed. \n5. When an attack hits, the target takes damage based on the attacker's power. If a unit's health drops to 0, it is eliminated and removed from the battlefield. \n6. If all enemies are eliminated, the player wins. If any enemy successfully reaches the left side of the battlefield, the player loses."
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              106,
              588,
              195,
              600
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  588,
                  195,
                  600
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      588,
                      195,
                      600
                    ],
                    "type": "text",
                    "content": "A.1.2 Human units"
                  }
                ]
              }
            ],
            "index": 5,
            "level": 1
          },
          {
            "type": "table",
            "bbox": [
              102,
              610,
              528,
              711
            ],
            "blocks": [
              {
                "bbox": [
                  102,
                  610,
                  528,
                  711
                ],
                "lines": [
                  {
                    "bbox": [
                      102,
                      610,
                      528,
                      711
                    ],
                    "spans": [
                      {
                        "bbox": [
                          102,
                          610,
                          528,
                          711
                        ],
                        "type": "table",
                        "html": "<table><tr><td>Unit</td><td>Attributes</td></tr><tr><td>HandgunSoldier</td><td>Health: 3, Shooting interval: 1000ms, Cost: 100, Damage per shot: 1, No special abilities.</td></tr><tr><td>RifleSoldier</td><td>Health: 3, Shooting interval: 500ms, Cost: 200, Damage per shot: 1, No special abilities.</td></tr><tr><td>MachineGunSoldier</td><td>Health: 3, Shooting interval: 250ms, Cost: 400, Damage per shot: 1, No special abilities.</td></tr></table>",
                        "image_path": "b9aff4c01fd1e3891db6244956d5ea156abf0ef639b842ea0504b30fff5bd0e7.jpg"
                      }
                    ]
                  }
                ],
                "index": 6,
                "type": "table_body"
              }
            ],
            "index": 6
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 11
      },
      {
        "para_blocks": [
          {
            "type": "table",
            "bbox": [
              105,
              72,
              528,
              353
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  72,
                  528,
                  353
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      72,
                      528,
                      353
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          72,
                          528,
                          353
                        ],
                        "type": "table",
                        "html": "<table><tr><td>ShieldSoldier</td><td>Health: 15, Cost: 50, Only for defense, no attack capabilities.</td></tr><tr><td>EnhancedShieldSoldier</td><td>Health: 30, Cost: 100, Only for defense, no attack capabilities and Bouncing Demon cannot jump over.</td></tr><tr><td>FlamethrowerSoldier</td><td>Health: 2, Cost: 200, Shooting interval: 1000ms, Damage per shot: 1, Deals an additional 1 damage every 1000ms.</td></tr><tr><td>IceSoldier</td><td>Health: 2, Shooting interval: 1000ms, Cost: 200, Damage per shot: 1, Reduces enemy speed by half.</td></tr><tr><td>AntiAirSoldier</td><td>Health: 2, Shooting interval: 1000ms, Cost: 175, Damage per shot: 1, Can attack airborne units.</td></tr><tr><td>Bomb</td><td>Health: 50, Detonation time: 500ms, Cost: 200, Explosion range: 3×3, Damage per explosion: 30, Destroyed after detonation.</td></tr><tr><td>LinearExplosion</td><td>Health: 50, Detonation time: 500ms, Cost: 200, Explosion range: the entire row, Damage per explosion: 30, Destroyed after detonation.</td></tr><tr><td>MagneticSoldier</td><td>Health: 2, Shooting interval: 2000ms, Cost: 100, Damage per shot: 0, Releases a magnetic pulse that disables the defensive abilities of ShieldDemon and MachineDemon.</td></tr><tr><td>LightMage</td><td>Health: 2, Damage per shot: 0, Cost: 150, No attack capabilities, Changes the attributes of bullets in the same row, converting their damage type to light.</td></tr><tr><td>RocketLauncherSoldier</td><td>Health: 2, Shooting interval: 1000ms, Damage per shot: 2, Cost: 600, Launches rockets, dealing damage to enemies within one grid.</td></tr></table>",
                        "image_path": "8604d968ca64ca4307e90323c598f93a03f13088228204f9ec2dc423414b2a36.jpg"
                      }
                    ]
                  }
                ],
                "index": 0,
                "type": "table_body"
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              106,
              371,
              195,
              383
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  371,
                  195,
                  383
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      371,
                      195,
                      383
                    ],
                    "type": "text",
                    "content": "A.1.3 Demon units"
                  }
                ]
              }
            ],
            "index": 1,
            "level": 1
          },
          {
            "bbox": [
              105,
              389,
              441,
              402
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  389,
                  441,
                  402
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      389,
                      441,
                      402
                    ],
                    "type": "text",
                    "content": "Note: A speed of 2 requires 14 seconds to travel from spawn to the last human grid."
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "type": "table",
            "bbox": [
              105,
              412,
              528,
              712
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  412,
                  528,
                  712
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      412,
                      528,
                      712
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          412,
                          528,
                          712
                        ],
                        "type": "table",
                        "html": "<table><tr><td>Unit</td><td>Attributes</td></tr><tr><td>NormalDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 100, Damage per attack: 1, No special abilities.</td></tr><tr><td>GreatDemon</td><td>Health: 20, Speed: 2, Attack interval: 1000ms, Cost: 175, Damage per attack: 1, Higher health.</td></tr><tr><td>DemonKing</td><td>Health: 100, Speed: 2, Attack interval: 1000ms, Cost: 800, Damage per attack: 5.</td></tr><tr><td>SpeedyDemon</td><td>Health: 10, Speed: 4, Attack interval: 1000ms, Cost: 150, Damage per attack: 1, Moves faster.</td></tr><tr><td>ShieldDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 175, Damage per attack: 1, Takes 70% less damage from normal attacks.</td></tr><tr><td>MachineDemon</td><td>Health: 20, Speed: 2 (increases to 3 when activated), Attack interval: 1000ms, Cost: 250, Damage per attack: 3, Reduced damage due to mechanical body.</td></tr><tr><td>BouncingDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 150, Damage per attack: 1, Can jump over certain units except for the EnhancedShieldSoldier.</td></tr><tr><td>ShieldBreakerDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 150, Damage per attack: 1 (×5 against shield units).</td></tr><tr><td>FireDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 150, Damage per attack: 1, Immune to fire damage.</td></tr><tr><td>FrostDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 150, Damage per attack: 1, Immune to ice damage and unaffected by slow effects.</td></tr></table>",
                        "image_path": "68cba328184727dea179f4992505c74fbf59cb8b11285307eaca35aa5fe7729c.jpg"
                      }
                    ]
                  }
                ],
                "index": 3,
                "type": "table_body"
              }
            ],
            "index": 3
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 12
      },
      {
        "para_blocks": [
          {
            "type": "table",
            "bbox": [
              106,
              72,
              528,
              175
            ],
            "blocks": [
              {
                "bbox": [
                  106,
                  72,
                  528,
                  175
                ],
                "lines": [
                  {
                    "bbox": [
                      106,
                      72,
                      528,
                      175
                    ],
                    "spans": [
                      {
                        "bbox": [
                          106,
                          72,
                          528,
                          175
                        ],
                        "type": "table",
                        "html": "<table><tr><td>FlyingDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 200, Damage per attack: 1, Only affected by anti-air attacks and can pass through human units directly.</td></tr><tr><td>ShadowDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 300, Damage per attack: 1, Can cast dark magic, making same-row allies immune to non-light damage.</td></tr><tr><td>SummoningDemon</td><td>Health: 10, Speed: 1, Attack interval: 1000ms, Cost: 300, Damage per attack: 1, Summons a Normal Demon to the left grid every 5000ms.</td></tr></table>",
                        "image_path": "23c2b0f4d7558ad29ffe7027d0f1cb2886660a6321109db739a4454ed45fbe1f.jpg"
                      }
                    ]
                  }
                ],
                "index": 0,
                "type": "table_body"
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              107,
              191,
              206,
              204
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  191,
                  206,
                  204
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      191,
                      206,
                      204
                    ],
                    "type": "text",
                    "content": "A.2 Battle card game"
                  }
                ]
              }
            ],
            "index": 1,
            "level": 1
          },
          {
            "bbox": [
              107,
              211,
              189,
              223
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  211,
                  189,
                  223
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      211,
                      189,
                      223
                    ],
                    "type": "text",
                    "content": "A.2.1 Game rules"
                  }
                ]
              }
            ],
            "index": 2,
            "level": 1
          },
          {
            "bbox": [
              105,
              228,
              506,
              412
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  228,
                  506,
                  412
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      228,
                      506,
                      412
                    ],
                    "type": "text",
                    "content": "1. At the start of the game, players can purchase all desired characters at once, up to a maximum of 7 characters. Gold characters cost three times as much as bronze characters, but their stats (attack, health, numerical skill effects, etc.) are twice as high. Non-numerical skills are not affected by this multiplier.  \n2. Initiative Determination: The side with more characters attacks first. If both sides have the same number of characters, the invader attacks first.  \n3. Elemental Advantage: Certain elements have an advantage over others, granting a bonus in combat (Fire > Nature, Nature > Water, Water > Earth, Earth > Fire).  \n4. Battle Process: Both sides will attack based on their respective target_priority (target priority). However, if there are Taunt minions on the opponent's side, attackers must prioritize attacking them. The attack order follows a left-to-right sequence. The first minion in the invaders or defenders fist (as defined in the JSON file) will attack first, depending on which side has the initiative. After that, the first minion from the opposing side attacks. Then, the second minion from the attacking side follows, then the second minion from the opposing side, and so on in an alternating pattern. If a minion's health reaches zero, it is eliminated. The battle continues with both sides attacking in turns until one side is completely wiped out, resulting in victory for the other side.  \n5. If all characters on one side are eliminated, the other side wins.  \n6. If both sides are eliminated simultaneously in the same attack resolution, the Invader wins."
                  }
                ]
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              105,
              414,
              372,
              424
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  414,
                  372,
                  424
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      414,
                      372,
                      424
                    ],
                    "type": "text",
                    "content": "5. If all characters on one side are eliminated, the other side wins."
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              105,
              424,
              481,
              436
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  424,
                  481,
                  436
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      424,
                      481,
                      436
                    ],
                    "type": "text",
                    "content": "6. If both sides are eliminated simultaneously in the same attack resolution, the Invader wins."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              107,
              447,
              198,
              458
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  447,
                  198,
                  458
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      447,
                      198,
                      458
                    ],
                    "type": "text",
                    "content": "A.2.2 Invader units"
                  }
                ]
              }
            ],
            "index": 6,
            "level": 1
          },
          {
            "type": "table",
            "bbox": [
              102,
              468,
              528,
              709
            ],
            "blocks": [
              {
                "bbox": [
                  102,
                  468,
                  528,
                  709
                ],
                "lines": [
                  {
                    "bbox": [
                      102,
                      468,
                      528,
                      709
                    ],
                    "spans": [
                      {
                        "bbox": [
                          102,
                          468,
                          528,
                          709
                        ],
                        "type": "table",
                        "html": "<table><tr><td>Unit</td><td>Attributes</td></tr><tr><td>FireLizard</td><td>Attack: 2, Health: 2, Cost: 1, Ability: Deals 2 damage to the enemy that killed it upon death.</td></tr><tr><td>WaterElemental</td><td>Attack: 2, Health: 2, Cost: 1, Ability: Gains +1 Attack when attacking.</td></tr><tr><td>PoisonFrog</td><td>Attack: 1, Health: 1, Cost: 2, Ability: Instantly destroys any minion it damages.</td></tr><tr><td>MoltenBound</td><td>Attack: 3, Health: 1, Cost: 2, Ability: Deals 1 damage to all enemies upon death.</td></tr><tr><td>BattleFenry</td><td>Attack: 7, Health: 4, Cost: 2, Ability: Each attack reduces its Attack by 4.</td></tr><tr><td>BanditLeader</td><td>Attack: 8, Health: 3, Cost: 3, Ability: Any excess damage from an attack carries over to the next target.</td></tr><tr><td>LavaGolem</td><td>Attack: 1, Health: 8, Cost: 3, Ability: Forces enemies to attack this minion first, Burns the attacker for 3 damage per turn when hit.</td></tr><tr><td>TideGuardian</td><td>Attack: 4, Health: 2, Cost: 3, Ability: Absorbs the first source of damage taken (divine shield), Attacks twice each turn.</td></tr><tr><td>TideLord</td><td>Attack: 4, Health: 9, Cost: 5, Ability: Doubles its Attack when taking damage.</td></tr></table>",
                        "image_path": "226f588d512091802bafb8aa6d6b1ccf2cc424e0325660755bc187a746017a22.jpg"
                      }
                    ]
                  }
                ],
                "index": 7,
                "type": "table_body"
              }
            ],
            "index": 7
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 13
      },
      {
        "para_blocks": [
          {
            "type": "table",
            "bbox": [
              108,
              72,
              525,
              137
            ],
            "blocks": [
              {
                "bbox": [
                  108,
                  72,
                  525,
                  137
                ],
                "lines": [
                  {
                    "bbox": [
                      108,
                      72,
                      525,
                      137
                    ],
                    "spans": [
                      {
                        "bbox": [
                          108,
                          72,
                          525,
                          137
                        ],
                        "type": "table",
                        "html": "<table><tr><td>Phoenix</td><td>Attack: 5, Health: 5, Cost: 5, Ability: Deals damage equal to its Attack to the target and its adjacent enemies, Revives with full Health after being defeated once per game.</td></tr><tr><td>ShadowOverlord</td><td>Attack: 4, Health: 4, Cost: 5, Ability: Summons a Slow Skeleton (3/1) upon death.</td></tr></table>",
                        "image_path": "23761357ee7b1976e0551fc8893e7a0f5da98323e1e04fc0f172d2c92ed018d8.jpg"
                      }
                    ]
                  }
                ],
                "index": 0,
                "type": "table_body"
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              107,
              155,
              203,
              167
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  155,
                  203,
                  167
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      155,
                      203,
                      167
                    ],
                    "type": "text",
                    "content": "A.2.3 Defender units"
                  }
                ]
              }
            ],
            "index": 1,
            "level": 1
          },
          {
            "type": "table",
            "bbox": [
              105,
              178,
              528,
              483
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  178,
                  528,
                  483
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      178,
                      528,
                      483
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          178,
                          528,
                          483
                        ],
                        "type": "table",
                        "html": "<table><tr><td>Unit</td><td>Attributes</td></tr><tr><td>Sapling</td><td>Attack: 2, Health: 2, Cost: 1, Ability: Gains +1 Health when attacking.</td></tr><tr><td>Rock Beetle</td><td>Attack: 1, Health: 5, Cost: 1, Ability: Forces enemies to attack this minion before others.</td></tr><tr><td>ForestSeer</td><td>Attack: 2, Health: 2, Cost: 2, Ability: At the start of the game, grants +1 Attack and +2 Health to all Nature Allies.</td></tr><tr><td>Stone Warrior</td><td>Attack: 2, Health: 5, Cost: 2, Ability: Forces enemies to attack this minion before others. Summons a Rock Beetle upon death.</td></tr><tr><td>Elite Soldier</td><td>Attack: 1, Health: 1, Cost: 2, Ability: At the start of the game, grants Divine Shield to adjacent minions and +1 Attack.</td></tr><tr><td>Paladin</td><td>Attack: 3, Health: 6, Cost: 3, Ability: Has Divine Shield; gains +2 Attack whenever a friendly minion loses its Divine Shield.</td></tr><tr><td>BlackRock</td><td>Attack: 5, Health: 1, Cost: 3, Ability: At the start of the game, gains +3 Health for each friendly minion.</td></tr><tr><td>Vine Protector</td><td>Attack: 5, Health: 4, Cost: 3, Ability: Upon death, restores 2 Health to all friendly minions.</td></tr><tr><td>King</td><td>Attack: 3, Health: 10, Cost: 5, Ability: Summons a 2/2 Soldier with Divine Shield whenever it attacks (if there is an open space).</td></tr><tr><td>MountainGiant</td><td>Attack: 4, Health: 9, Cost: 5, Ability: Forces enemies to attack this minion first, Reduces the attack of the attacker by 2 when hit.</td></tr><tr><td>AncientTreant</td><td>Attack: 4, Health: 4, Cost: 5, Ability: At the start of the game, grants +3 Attack and +3 Health to all allied minions.</td></tr></table>",
                        "image_path": "a1b4da11ff1628a0133447e50017a584d6e270c02d2d6a4e81bd6b4a17c2c3c3.jpg"
                      }
                    ]
                  }
                ],
                "index": 2,
                "type": "table_body"
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              107,
              501,
              247,
              513
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  501,
                  247,
                  513
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      501,
                      247,
                      513
                    ],
                    "type": "text",
                    "content": "A.3 Turn-based attribute game"
                  }
                ]
              }
            ],
            "index": 3,
            "level": 1
          },
          {
            "bbox": [
              106,
              521,
              189,
              533
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  521,
                  189,
                  533
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      521,
                      189,
                      533
                    ],
                    "type": "text",
                    "content": "A.3.1 Game rules"
                  }
                ]
              }
            ],
            "index": 4,
            "level": 1
          },
          {
            "bbox": [
              105,
              537,
              506,
              681
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  537,
                  506,
                  681
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      537,
                      506,
                      681
                    ],
                    "type": "text",
                    "content": "1. This game is a turn-based character battle game divided into two factions: Invader and Defender. Each faction consists of three characters. The Invader faction includes Fire, Water, and Dark elements, while the Defender faction includes Wood, Earth, and Light elements. Characters appear and act in the order they are listed in the data. \n2. Combat proceeds in rounds. In each round, the three Invader characters act first in order, followed by the three Defender characters. The sequence then repeats in the next round. \n3. Each character has three skills that are used in a preset, looping sequence. On each turn, a character uses the next skill in their list and continues cycling through them in order. \n4. The game features an elemental effectiveness system: Fire beats Wood, Wood beats Earth, Earth beats Water, and Water beats Fire (1.2× damage when effective, 0.8× when resisted). Light and Dark counter each other with 1.5× damage. All other combinations deal the standard 1.0× damage. \n5. If all characters on one side are eliminated, the other side wins."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              106,
              692,
              198,
              703
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  692,
                  198,
                  703
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      692,
                      198,
                      703
                    ],
                    "type": "text",
                    "content": "A.3.2 Invader skills"
                  }
                ]
              }
            ],
            "index": 6,
            "level": 1
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 14
      },
      {
        "para_blocks": [
          {
            "type": "table",
            "bbox": [
              105,
              77,
              528,
              533
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  77,
                  528,
                  533
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      77,
                      528,
                      533
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          77,
                          528,
                          533
                        ],
                        "type": "table",
                        "html": "<table><tr><td>Skill Name</td><td>Description</td></tr><tr><td>Fire Skills</td><td></td></tr><tr><td>flame_splash</td><td>Deals 12 damage and applies Burning for 2 rounds (1 layer, 5 damage per round). Cost: 1</td></tr><tr><td>residual_warmth</td><td>Increases the damage of the next fire-based skill by 30% for 1 round. Cost: 1</td></tr><tr><td>burst_flame_bomb</td><td>Deals 25 base damage, plus 3 additional damage for each Burning layer on the target. Cost: 2</td></tr><tr><td>flame_whirlwind</td><td>Applies 4 layers of Burning to the target, lasting 2 rounds. Each layer deals 5 damage per round. Cost: 2</td></tr><tr><td>magma_eruption</td><td>Deals 40 base damage, plus 5 extra damage per Burning layer. Removes all Burning after the attack. Cost: 3</td></tr><tr><td>hell_curtain</td><td>Deals 35 damage and grants a shield that reflects 30 melee damage, lasting 2 rounds (1 layer). Cost: 3</td></tr><tr><td>Water Skills</td><td></td></tr><tr><td>stream_pierce</td><td>Deals 10 damage and grants 1 permanent layer of Tidal Surge. Cost: 1</td></tr><tr><td>water_bARRIER</td><td>Grants a 5-point shield for 3 rounds and increases Tidal Surge by 1 layer. Cost: 1</td></tr><tr><td>whirlpool_strangle</td><td>Deals 20 base damage, plus 4 additional damage per Tidal Surge layer. Cost: 2</td></tr><tr><td>ice_branched</td><td>Deals 15 damage and causes the target to take 50% more damage next turn (1 round). Cost: 2</td></tr><tr><td>tsunami_ending</td><td>Deals 30 base damage, plus 5 additional damage per Tidal Surge layer. Removes all Tidal Surge after the attack. Cost: 3</td></tr><tr><td>abyss_resonance</td><td>Deals 3 damage per Tidal Surge layer and grants a shield worth 6 per layer, lasting 3 rounds. Cost: 3</td></tr><tr><td>Dark Skills</td><td></td></tr><tr><td>shadow_claw</td><td>Deals 14 damage and heals the user for 30% of the damage dealt (rounded down). Cost: 1</td></tr><tr><td>fear_whisper</td><td>Reduces the target&#x27;s damage taken by 10% for 3 rounds (1 layer). Cost: 1</td></tr><tr><td>soul_siphon</td><td>Deals 25 damage. If the target&#x27;s HP is below 50%, deals an extra 15 damage. Cost: 2</td></tr><tr><td>night_ambush</td><td>Deals 20 damage and causes the target to take 20% more damage next turn (1 round). Cost: 2</td></tr><tr><td>final_announcement</td><td>Deals 45 base damage, plus 5 extra damage for every 10% HP the target has lost. Cost: 3</td></tr><tr><td>void_assimilation</td><td>Sacrifices 20% of current HP to deal penetration damage equal to twice the HP sacrificed. Cost: 3</td></tr></table>",
                        "image_path": "ec263e806dcf4244963eddf519012bf7994b4362701bc90b9372e21782fc1a2b.jpg"
                      }
                    ]
                  }
                ],
                "index": 0,
                "type": "table_body"
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              106,
              552,
              204,
              564
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  552,
                  204,
                  564
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      552,
                      204,
                      564
                    ],
                    "type": "text",
                    "content": "A.3.3 Defender skills"
                  }
                ]
              }
            ],
            "index": 1,
            "level": 1
          },
          {
            "type": "table",
            "bbox": [
              105,
              574,
              526,
              719
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  574,
                  526,
                  719
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      574,
                      526,
                      719
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          574,
                          526,
                          719
                        ],
                        "type": "table",
                        "html": "<table><tr><td>Skill Name</td><td>Description</td></tr><tr><td>Wood Skills</td><td></td></tr><tr><td>bud_healing</td><td>Grants Bud Healing for 3 rounds, restoring 6 HP per round. Cost: 1</td></tr><tr><td>parasitic_seed</td><td>Applies Parasitic Seed for 3 rounds, immediately deals 10 damage. The target takes 5 counter damage each time they attack. Cost: 1</td></tr><tr><td>life_totem</td><td>Restores 25 HP and grants Life Totem for 3 rounds, increasing healing received by 10%. Cost: 2</td></tr><tr><td>natural_purification</td><td>Removes negative statuses from the user and deals 30 damage to the target. Cost: 2</td></tr><tr><td>forest_reincarnation</td><td>Restores 60 HP. If it exceeds max HP, the excess is converted into a shield (50% of excess HP) for 3 rounds. Also deals 20 damage to an enemy. Cost: 3</td></tr></table>",
                        "image_path": "bbec2708484d9b24d218542e7ad5192a72cf5a6bc693be66055ff51f84614cd3.jpg"
                      }
                    ]
                  }
                ],
                "index": 2,
                "type": "table_body"
              }
            ],
            "index": 2
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 15
      },
      {
        "para_blocks": [
          {
            "type": "table",
            "bbox": [
              105,
              87,
              526,
              380
            ],
            "blocks": [
              {
                "bbox": [
                  105,
                  87,
                  526,
                  380
                ],
                "lines": [
                  {
                    "bbox": [
                      105,
                      87,
                      526,
                      380
                    ],
                    "spans": [
                      {
                        "bbox": [
                          105,
                          87,
                          526,
                          380
                        ],
                        "type": "table",
                        "html": "<table><tr><td colspan=\"2\">Earth Skills</td></tr><tr><td>rock armor</td><td>Grants 12 shield for 3 rounds and reflects 5 melee damage while the shield is active. Cost: 1</td></tr><tr><td>earth_shock</td><td>Deals 20 damage. Cost: 1</td></tr><tr><td>granite_barrier</td><td>Grants Granite Barrier for 3 rounds, decreasing damage by 40%. Cost: 2</td></tr><tr><td>quicksand Trap</td><td>Applies Quicksand Trap for 3 rounds. The target&#x27;s next 3 damage are delayed by 20% and each trigger deals 10 damage. Cost: 2</td></tr><tr><td>earth_pulse</td><td>Grants shield based on HP lost (8 shield per 10% HP lost), lasting permanently. Cost: 3</td></tr><tr><td>core_rebound</td><td>Deals 80% of stored damage to the target. Clears stored damage after use. Cost: 3</td></tr><tr><td colspan=\"2\">Light Skills</td></tr><tr><td>holy_glimmer</td><td>Removes a negative status (if any) and restores 8 HP to the user. Also deals 8 light damage to an enemy. Cost: 1</td></tr><tr><td>faith Emblem</td><td>Grants Faith Emblem for 1 round. The next damage taken is reduced by 20% and converted into healing. When triggered, deals 10 damage to the attacker. Cost: 1</td></tr><tr><td>divine_link</td><td>Grants Divine Link for 1 round. The next damage taken is reflected back to the attacker. Cost: 2</td></tr><tr><td>luminous_dispel</td><td>Removes one buff from the target (if any) and applies a debuff for 2 rounds that reduces their attack by 15%. Cost: 2</td></tr><tr><td>angelic_sanctuary</td><td>Grants Angelic Sanctuary for 3 rounds, reducing all incoming damage by 30 points. Cost: 3</td></tr><tr><td>divine_sword</td><td>Deals 20 damage and grants a buff that increases the next skill&#x27;s damage by 20. Cost: 3</td></tr></table>",
                        "image_path": "8f2de641797dee13f63e742de7b9f5b032062700cb8e339b5c5c9a1c3bba5d1c.jpg"
                      }
                    ]
                  }
                ],
                "index": 0,
                "type": "table_body"
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              107,
              401,
              280,
              415
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  107,
                  401,
                  280,
                  415
                ],
                "spans": [
                  {
                    "bbox": [
                      107,
                      401,
                      280,
                      415
                    ],
                    "type": "text",
                    "content": "B Additional evaluation metrics"
                  }
                ]
              }
            ],
            "index": 1,
            "level": 1
          },
          {
            "bbox": [
              106,
              426,
              504,
              448
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  426,
                  504,
                  448
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      426,
                      504,
                      448
                    ],
                    "type": "text",
                    "content": "This section details supplementary metrics used to provide a more granular understanding of LLM behavior in strategic game environments, complementing the core metrics presented in Section 3.4."
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              106,
              460,
              244,
              473
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  460,
                  244,
                  473
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      460,
                      244,
                      473
                    ],
                    "type": "text",
                    "content": "B.1 Rule violation Rate (RVR)"
                  }
                ]
              }
            ],
            "index": 3,
            "level": 1
          },
          {
            "bbox": [
              105,
              481,
              506,
              571
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  481,
                  506,
                  571
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": "This metric measures how often a model's initial strategy proposal fails to adhere to the game's explicit rules, particularly budget constraints. Let "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " denote model "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "i"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " Let "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "T_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " be the total number of initial strategy proposals made by model "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " across all games and rounds where it provides an initial strategy. For each initial strategy proposal "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "S_{i,t}^{(0)}"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " (where "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "t"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " indexes these proposals, "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "t\\in \\{1,\\ldots ,T_i\\})"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " let "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "V(S_{i,t}^{(0)})"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " be an indicator function, such that "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "V(S_{i,t}^{(0)}) = 1"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " if the strategy "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "S_{i,t}^{(0)}"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " violates any game rule (including budget constraints), and "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "V(S_{i,t}^{(0)}) = 0"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " otherwise. The Rule Violation Rate for model "
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      481,
                      506,
                      571
                    ],
                    "type": "text",
                    "content": " is:"
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              254,
              567,
              504,
              599
            ],
            "type": "interline_equation",
            "lines": [
              {
                "bbox": [
                  254,
                  567,
                  504,
                  599
                ],
                "spans": [
                  {
                    "bbox": [
                      254,
                      567,
                      504,
                      599
                    ],
                    "type": "interline_equation",
                    "content": "\\mathrm{RVR}_i = \\frac{\\sum_{t = 1}^{T_i}V(S_{i,t}^{(0)})}{T_i} \\tag{1}",
                    "image_path": "a12bb84f0e1ed888ae8d45826cb1572e5e103fd885da26158c4cd3aab5fd33dc.jpg"
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              105,
              601,
              479,
              613
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  601,
                  479,
                  613
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      601,
                      479,
                      613
                    ],
                    "type": "text",
                    "content": "A lower RVR indicates better adherence to explicit constraints during initial planning phases."
                  }
                ]
              }
            ],
            "index": 6
          },
          {
            "bbox": [
              106,
              625,
              250,
              637
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  625,
                  250,
                  637
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      625,
                      250,
                      637
                    ],
                    "type": "text",
                    "content": "B.2 Constructive Rate (CnstrR)"
                  }
                ]
              }
            ],
            "index": 7,
            "level": 1
          },
          {
            "bbox": [
              105,
              645,
              505,
              722
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  645,
                  505,
                  722
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": "This metric assesses whether a correction attempt, following negative feedback, leads to an objectively improved game state, even if it doesn't immediately result in a win or full rule compliance. Let "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "E_{i,g,k}"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": " be the event that negative feedback is received for strategy "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "S_{i,g,k}"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": " (model "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "i"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": ", game instance "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "g"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": ", "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "k"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": "- th strategy in that game instance). Let "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "A_{i,g,k + 1}"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": " be the event that model "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": " proposes a new strategy "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "S_{i,g,k + 1}"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": " in response. Let "
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "inline_equation",
                    "content": "\\Phi (S)"
                  },
                  {
                    "bbox": [
                      105,
                      645,
                      505,
                      722
                    ],
                    "type": "text",
                    "content": " be a game- specific state evaluation function where higher values indicate a more advantageous position for the model (e.g., based on remaining unit health/cost difference, reduced enemy threat, or other heuristic measures of game state quality). A correction"
                  }
                ]
              }
            ],
            "index": 8
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 16
      },
      {
        "para_blocks": [
          {
            "bbox": [
              105,
              72,
              504,
              94
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  72,
                  504,
                  94
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      94
                    ],
                    "type": "inline_equation",
                    "content": "S_{i,g,k + 1}"
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      94
                    ],
                    "type": "text",
                    "content": " is considered constructive if "
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      94
                    ],
                    "type": "inline_equation",
                    "content": "\\Phi (S_{i,g,k + 1}) > \\Phi (S_{i,g,k})"
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      94
                    ],
                    "type": "text",
                    "content": ". The Constructive Rate for model "
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      94
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      94
                    ],
                    "type": "text",
                    "content": " is:"
                  }
                ]
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              146,
              91,
              504,
              128
            ],
            "type": "interline_equation",
            "lines": [
              {
                "bbox": [
                  146,
                  91,
                  504,
                  128
                ],
                "spans": [
                  {
                    "bbox": [
                      146,
                      91,
                      504,
                      128
                    ],
                    "type": "interline_equation",
                    "content": "\\mathrm{CnstrR}_i = \\frac{\\sum_{g = 1}^{G_i}\\sum_{k = 0}^{K_{i,g} - 1}\\mathbb{I}(E_{i,g,k}\\wedge A_{i,g,k + 1}\\wedge(\\Phi(S_{i,g,k + 1}) > \\Phi(S_{i,g,k})))}{\\sum_{g = 1}^{G_i}\\sum_{k = 0}^{K_{i,g} - 1}\\mathbb{I}(E_{i,g,k}\\wedge A_{i,g,k + 1}) + \\epsilon} \\tag{2}",
                    "image_path": "f0868a505cdcbccd339a99a581790d6d7fd875e96598c3e40290765d1ed2caef.jpg"
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              106,
              132,
              505,
              188
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  132,
                  505,
                  188
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "text",
                    "content": "where "
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "inline_equation",
                    "content": "G_{i}"
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "text",
                    "content": " is the total number of game instances involving model "
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "text",
                    "content": " where corrections are possible, "
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "inline_equation",
                    "content": "K_{i,g}"
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "text",
                    "content": " is the number of strategies proposed by model "
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "text",
                    "content": " in game instance "
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "inline_equation",
                    "content": "g,\\mathbb{I}(\\cdot)"
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "text",
                    "content": " is the indicator function, and "
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "inline_equation",
                    "content": "\\epsilon"
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "text",
                    "content": " is a small constant to prevent division by zero. This captures the tendency for revisions to make incremental, positive progress. Calculating "
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "inline_equation",
                    "content": "\\Phi (S)"
                  },
                  {
                    "bbox": [
                      106,
                      132,
                      505,
                      188
                    ],
                    "type": "text",
                    "content": " requires domain- specific heuristics tailored to each game environment."
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              106,
              202,
              334,
              215
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  202,
                  334,
                  215
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      202,
                      334,
                      215
                    ],
                    "type": "text",
                    "content": "B.3 Multi-aspect Strategic Similarity Ratio "
                  },
                  {
                    "bbox": [
                      106,
                      202,
                      334,
                      215
                    ],
                    "type": "inline_equation",
                    "content": "(S_{\\mathrm{MASR}})"
                  }
                ]
              }
            ],
            "index": 3,
            "level": 1
          },
          {
            "bbox": [
              106,
              222,
              505,
              270
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  222,
                  505,
                  270
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": "This metric assesses the similarity between a corrected strategy "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "S^{(k + 1)}"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": " and the preceding strategy "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "S^{(k)}"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": " by considering multiple facets: structural, semantic, and functional similarity. For a given model "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": ", let "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "S_{i,g,k}"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": " be the "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "k"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": "- th strategy in game instance "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "g"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": ". Let "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{Sim}_{\\mathrm{struct}}(S^{\\prime},S)"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": ", "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{Sim}_{\\mathrm{sem}}(S^{\\prime},S)"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": ", and "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{Sim}_{\\mathrm{func}}(S^{\\prime},S)"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": " be normalized similarity scores in "
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "inline_equation",
                    "content": "[0,1]"
                  },
                  {
                    "bbox": [
                      106,
                      222,
                      505,
                      270
                    ],
                    "type": "text",
                    "content": " for these aspects:"
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              105,
              273,
              506,
              415
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  273,
                  506,
                  415
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": "- Structural Similarity "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "(\\mathrm{Sim}_{\\mathrm{struct}})"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ": Measures overlap in concrete elements (e.g., unit types, positions, configurations). This can be quantified using metrics like the Jaccard index on sets of chosen units/actions, or a normalized graph edit distance if strategies are represented as graphs "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "G(S)"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ". For instance, "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{Sim}_{\\mathrm{struct}}(S^{\\prime},S) = 1 - \\frac{\\mathrm{GED}(G(S^{\\prime}),G(S^{\\prime})}{\\mathrm{max} \\cdot \\mathrm{GED}}"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ", where GED is graph edit distance.- Semantic Similarity "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "(\\mathrm{Sim}_{\\mathrm{sem}})"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ": Measures similarity in the underlying strategic intent or concept, often derived from embeddings of textual descriptions or structured representations of the strategy. If "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "\\mathbf{e}(S)"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": " is an embedding vector for strategy "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "S"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ", then "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{Sim}_{\\mathrm{sem}}(S^{\\prime},S) = \\max (0,\\text{cosine similarity} (\\mathbf{e}(S^{\\prime}),\\mathbf{e}(S)))"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ".- Functional Similarity "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "(\\mathrm{Sim}_{\\mathrm{func}})"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ": Measures overlap in the intended strategic functions or roles fulfilled by the strategy components (e.g., defensive formations, offensive pushes, resource gathering focus). If "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "\\mathcal{F}(S)"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": " is the set of strategic functions embodied by strategy "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "S"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ", then "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{Sim}_{\\mathrm{func}}(S^{\\prime},S) = \\frac{|\\mathcal{F}(S^{\\prime})\\cap\\mathcal{F}(S)|}{|\\mathcal{F}(S^{\\prime})\\cup\\mathcal{F}(S)| + \\epsilon^{\\prime}}"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": ", where "
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "inline_equation",
                    "content": "\\epsilon^{\\prime}"
                  },
                  {
                    "bbox": [
                      105,
                      273,
                      506,
                      415
                    ],
                    "type": "text",
                    "content": " prevents division by zero for empty sets."
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              105,
              418,
              504,
              441
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  418,
                  504,
                  441
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      418,
                      504,
                      441
                    ],
                    "type": "text",
                    "content": "The multi- aspect similarity ratio for a specific correction from "
                  },
                  {
                    "bbox": [
                      105,
                      418,
                      504,
                      441
                    ],
                    "type": "inline_equation",
                    "content": "S_{i,g,k}"
                  },
                  {
                    "bbox": [
                      105,
                      418,
                      504,
                      441
                    ],
                    "type": "text",
                    "content": " to "
                  },
                  {
                    "bbox": [
                      105,
                      418,
                      504,
                      441
                    ],
                    "type": "inline_equation",
                    "content": "S_{i,g,k + 1}"
                  },
                  {
                    "bbox": [
                      105,
                      418,
                      504,
                      441
                    ],
                    "type": "text",
                    "content": " is a weighted combination:"
                  }
                ]
              }
            ],
            "index": 6
          },
          {
            "bbox": [
              176,
              445,
              504,
              483
            ],
            "type": "interline_equation",
            "lines": [
              {
                "bbox": [
                  176,
                  445,
                  504,
                  483
                ],
                "spans": [
                  {
                    "bbox": [
                      176,
                      445,
                      504,
                      483
                    ],
                    "type": "interline_equation",
                    "content": "\\mathcal{S}_{\\mathrm{MASR}}(S_{i,g,k + 1},S_{i,g,k}) = \\sum_{j = 1}^{N_{\\mathrm{aspecs}}}\\theta_j\\cdot \\mathrm{Sim}_{\\mathrm{aspect}_j}(S_{i,g,k + 1},S_{i,g,k}) \\tag{3}",
                    "image_path": "e5f94b007a04690fcff92783fd9156501b0ba58b02a2b777b6570fa9cee7c05a.jpg"
                  }
                ]
              }
            ],
            "index": 7
          },
          {
            "bbox": [
              106,
              490,
              505,
              527
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  490,
                  505,
                  527
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "text",
                    "content": "where "
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "inline_equation",
                    "content": "N_{\\mathrm{aspecs}}"
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "text",
                    "content": " is the number of similarity aspects (e.g., 3 for structural, semantic, functional), and "
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "inline_equation",
                    "content": "\\theta_{j}"
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "text",
                    "content": " are weights such that "
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "inline_equation",
                    "content": "\\sum_{j = 1}^{N_{\\mathrm{aspecs}}}\\theta_{j} = 1"
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "text",
                    "content": " and "
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "inline_equation",
                    "content": "\\theta_{j}\\geq 0"
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "text",
                    "content": ". The average "
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "inline_equation",
                    "content": "\\bar{S}_{\\mathrm{MASR}}(i)"
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "text",
                    "content": " for model "
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      106,
                      490,
                      505,
                      527
                    ],
                    "type": "text",
                    "content": " is calculated over all valid correction steps:"
                  }
                ]
              }
            ],
            "index": 8
          },
          {
            "bbox": [
              153,
              533,
              504,
              568
            ],
            "type": "interline_equation",
            "lines": [
              {
                "bbox": [
                  153,
                  533,
                  504,
                  568
                ],
                "spans": [
                  {
                    "bbox": [
                      153,
                      533,
                      504,
                      568
                    ],
                    "type": "interline_equation",
                    "content": "\\mathcal{S}_{\\mathrm{MASR}}(i) = \\frac{\\sum_{g = 1}^{G_i}\\sum_{k = 0}^{K_{i,g} - 1}\\mathbb{I}(E_{i,g,k}\\wedge A_{i,g,k + 1})\\cdot\\mathcal{S}_{\\mathrm{MASR}}(S_{i,g,k + 1},S_{i,g,k})}{\\sum_{g = 1}^{G_i}\\sum_{k = 0}^{K_{i,g} - 1}\\mathbb{I}(E_{i,g,k}\\wedge A_{i,g,k + 1}) + \\epsilon} \\tag{4}",
                    "image_path": "6fdc32166aa74bd26be1579a2c246c7a47339b1db26119a65adf49c0df5dd017.jpg"
                  }
                ]
              }
            ],
            "index": 9
          },
          {
            "bbox": [
              106,
              574,
              505,
              610
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  574,
                  505,
                  610
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      574,
                      505,
                      610
                    ],
                    "type": "text",
                    "content": "This metric quantifies the degree of strategic preservation or alteration during revisions. A high "
                  },
                  {
                    "bbox": [
                      106,
                      574,
                      505,
                      610
                    ],
                    "type": "inline_equation",
                    "content": "\\bar{S}_{\\mathrm{MASR}}(i)"
                  },
                  {
                    "bbox": [
                      106,
                      574,
                      505,
                      610
                    ],
                    "type": "text",
                    "content": " indicates a tendency towards conservative revision, while a low value suggests more aggressive or radical strategy changes."
                  }
                ]
              }
            ],
            "index": 10
          },
          {
            "bbox": [
              106,
              624,
              264,
              636
            ],
            "type": "title",
            "lines": [
              {
                "bbox": [
                  106,
                  624,
                  264,
                  636
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      624,
                      264,
                      636
                    ],
                    "type": "text",
                    "content": "B.4 First-Mover Advantage (FMA)"
                  }
                ]
              }
            ],
            "index": 11,
            "level": 1
          },
          {
            "bbox": [
              105,
              644,
              505,
              723
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  644,
                  505,
                  723
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": "First- Mover Advantage (FMA) quantifies the performance difference for a model when it acts first (initiates the interaction or round) versus when it acts second (responds to the opponent's initial move). This can be calculated for various performance metrics "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "X"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": ", such as Win Rate (WR), Over- correction Risk Rate (ORR), or Correction Success Rate (CSR). Let "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " be the model under evaluation. Let "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "\\mathcal{G}_{i,\\mathrm{first}}"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " be the set of game instances where model "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " moved first, and "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "\\mathcal{G}_{i,\\mathrm{second}}"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " be the set of game instances where model "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " moved second. Let "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "N_{i,\\mathrm{first}}(X) = |\\mathcal{G}_{i,\\mathrm{first}}|"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " and "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "N_{i,\\mathrm{second}}(X) = |\\mathcal{G}_{i,\\mathrm{second}}|"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " be the respective counts of such game instances for which metric "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "X"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " is applicable. Let "
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "inline_equation",
                    "content": "X_{i,m}"
                  },
                  {
                    "bbox": [
                      105,
                      644,
                      505,
                      723
                    ],
                    "type": "text",
                    "content": " be the"
                  }
                ]
              }
            ],
            "index": 12
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 17
      },
      {
        "para_blocks": [
          {
            "bbox": [
              105,
              72,
              504,
              95
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  72,
                  504,
                  95
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "text",
                    "content": "value of metric "
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "inline_equation",
                    "content": "X"
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "text",
                    "content": " observed for model "
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "text",
                    "content": " in a specific game instance "
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "inline_equation",
                    "content": "m"
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "text",
                    "content": ". The average performance for model "
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "text",
                    "content": " on metric "
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "inline_equation",
                    "content": "X"
                  },
                  {
                    "bbox": [
                      105,
                      72,
                      504,
                      95
                    ],
                    "type": "text",
                    "content": " when moving first is:"
                  }
                ]
              }
            ],
            "index": 0
          },
          {
            "bbox": [
              226,
              99,
              504,
              130
            ],
            "type": "interline_equation",
            "lines": [
              {
                "bbox": [
                  226,
                  99,
                  504,
                  130
                ],
                "spans": [
                  {
                    "bbox": [
                      226,
                      99,
                      504,
                      130
                    ],
                    "type": "interline_equation",
                    "content": "\\bar{X}_{i,\\mathrm{first}} = \\frac{1}{N_{i,\\mathrm{first}}(X) + \\epsilon}\\sum_{m\\in \\mathcal{G}_{i,\\mathrm{first}}}X_{i,m} \\tag{5}",
                    "image_path": "e8ae4f150ce8f5b6d33c262d28b98f98a6af3f3b4d6259dc0703ed83baa5349b.jpg"
                  }
                ]
              }
            ],
            "index": 1
          },
          {
            "bbox": [
              105,
              136,
              455,
              148
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  136,
                  455,
                  148
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      136,
                      455,
                      148
                    ],
                    "type": "text",
                    "content": "Similarly, the average performance for model "
                  },
                  {
                    "bbox": [
                      105,
                      136,
                      455,
                      148
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      136,
                      455,
                      148
                    ],
                    "type": "text",
                    "content": " on metric "
                  },
                  {
                    "bbox": [
                      105,
                      136,
                      455,
                      148
                    ],
                    "type": "inline_equation",
                    "content": "X"
                  },
                  {
                    "bbox": [
                      105,
                      136,
                      455,
                      148
                    ],
                    "type": "text",
                    "content": " when moving second is:"
                  }
                ]
              }
            ],
            "index": 2
          },
          {
            "bbox": [
              215,
              152,
              504,
              183
            ],
            "type": "interline_equation",
            "lines": [
              {
                "bbox": [
                  215,
                  152,
                  504,
                  183
                ],
                "spans": [
                  {
                    "bbox": [
                      215,
                      152,
                      504,
                      183
                    ],
                    "type": "interline_equation",
                    "content": "\\bar{X}_{i,\\mathrm{second}} = \\frac{1}{N_{i,\\mathrm{second}}(X) + \\epsilon}\\sum_{m\\in \\mathcal{G}_{i,\\mathrm{second}}}X_{i,m} \\tag{6}",
                    "image_path": "3e7d48ae82718f4240a17c08e58987336720ddac38d96f2469d9e31c0a8aeae8.jpg"
                  }
                ]
              }
            ],
            "index": 3
          },
          {
            "bbox": [
              105,
              189,
              505,
              222
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  105,
                  189,
                  505,
                  222
                ],
                "spans": [
                  {
                    "bbox": [
                      105,
                      189,
                      505,
                      222
                    ],
                    "type": "text",
                    "content": "where "
                  },
                  {
                    "bbox": [
                      105,
                      189,
                      505,
                      222
                    ],
                    "type": "inline_equation",
                    "content": "\\epsilon"
                  },
                  {
                    "bbox": [
                      105,
                      189,
                      505,
                      222
                    ],
                    "type": "text",
                    "content": " is a small positive constant to prevent division by zero if a model never plays in one of the roles or if the metric is not applicable in those instances. The First- Mover Advantage for metric "
                  },
                  {
                    "bbox": [
                      105,
                      189,
                      505,
                      222
                    ],
                    "type": "inline_equation",
                    "content": "X"
                  },
                  {
                    "bbox": [
                      105,
                      189,
                      505,
                      222
                    ],
                    "type": "text",
                    "content": " and model "
                  },
                  {
                    "bbox": [
                      105,
                      189,
                      505,
                      222
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      105,
                      189,
                      505,
                      222
                    ],
                    "type": "text",
                    "content": " is then defined as the difference:"
                  }
                ]
              }
            ],
            "index": 4
          },
          {
            "bbox": [
              240,
              225,
              504,
              240
            ],
            "type": "interline_equation",
            "lines": [
              {
                "bbox": [
                  240,
                  225,
                  504,
                  240
                ],
                "spans": [
                  {
                    "bbox": [
                      240,
                      225,
                      504,
                      240
                    ],
                    "type": "interline_equation",
                    "content": "\\mathrm{FMA}_X(i) = X_{i,\\mathrm{first}} - \\bar{X}_{i,\\mathrm{second}} \\tag{7}",
                    "image_path": "9ace809444ae5e2ef179ec32028cddff745a218c92dca9a6c0f6c3ef790a1bc3.jpg"
                  }
                ]
              }
            ],
            "index": 5
          },
          {
            "bbox": [
              106,
              246,
              505,
              280
            ],
            "type": "text",
            "lines": [
              {
                "bbox": [
                  106,
                  246,
                  505,
                  280
                ],
                "spans": [
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "text",
                    "content": "A positive "
                  },
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{FMA}_X(i)"
                  },
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "text",
                    "content": " indicates that model "
                  },
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "inline_equation",
                    "content": "M_{i}"
                  },
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "text",
                    "content": " performs better on metric "
                  },
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "inline_equation",
                    "content": "X"
                  },
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "text",
                    "content": " when it has the first- move advantage. Conversely, a negative value suggests better performance when moving second. The magnitude of "
                  },
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "inline_equation",
                    "content": "\\mathrm{FMA}_X(i)"
                  },
                  {
                    "bbox": [
                      106,
                      246,
                      505,
                      280
                    ],
                    "type": "text",
                    "content": " indicates the strength of this turn- order bias."
                  }
                ]
              }
            ],
            "index": 6
          }
        ],
        "discarded_blocks": [],
        "page_size": [
          612,
          792
        ],
        "page_idx": 18
      }
    ],
    "_backend": "vlm",
    "_version_name": "2.0.6"
  },
  "md_content": "# Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making\n\nXiaopeng Yuan* Xingjian Zhang Ke Xu Yifan Xu Lijun Yu Jindong Wang\n\nYushun Dong Haohan Wang†\n\n# Abstract\n\nLarge language models (LLMs) are increasingly applied to tasks that require complex reasoning. While most benchmarks focus on evaluating final reasoning outcomes, they overlook the internal processes that lead to those outcomes—such as how a model plans, revises, and makes decisions under constraints. We argue that evaluating these internal reasoning steps is essential for understanding model behavior and improving reliability in real- world applications. To make these processes observable and measurable, we propose using strategic games as a natural and effective environment. These games operate within closed, rule- based systems and provide interpretable states, limited resources, and automatic feedback. Therefore, we propose a framework to evaluate LLMs along three core process dimensions: planning, revision, and resource- constrained decision making. To support this, we introduce a set of evaluation metrics that extend beyond traditional win rates, incorporating measures such as Over- correction Risk Rate, correction success rate, improvement slope, and over- budget ratio.\n\nIn a set of 4320 adversarial rounds across 12 state- of- the- art models, we find that ChatGPT- o3- mini, which demonstrates strong planning capabilities, achieves the highest composite process score (74.7% win rate, 78.6% correction success, and a +0.041 improvement slope). In contrast, Qwen- Plus, despite a high Overcorrection Risk Score of 81.6%, wins only 25.6% of its matches, primarily due to excessive resource use. We also observe a negative correlation between Over- correction Risk Rate and correction success rate (Pearson  $r = - 0.51$ ,  $p = 0.093$ ), suggesting that more frequent corrections do not always improve outcomes. This pattern may reflect impulsive revision strategies, where premature edits reduce overall effectiveness, while more selective approaches lead to greater accuracy. We hope this work offers a new direction for LLM evaluation—focusing not just on what models decide, but on how they decide it.\n\n# 1 Introduction\n\nLarge language models (LLMs) are now capable of solving increasingly complex reasoning tasks [14, 34]. As their performance on traditional benchmarks improves, it has become clear that measuring outcome accuracy alone is no longer sufficient. In many real- world scenarios, the quality of an LLM's reasoning depends not only on the final answer, but also on the internal processes it uses to arrive there: how it plans, how it revises mistakes, and how it makes decisions under resource constraints.\n\nWe argue that understanding these reasoning processes is a necessary next step in LLM evaluation. Current benchmarks—such as GSM8K [6] or MMLU—offer single- turn questions and measure correctness in isolation. They provide limited visibility into how a model generates hypotheses, updates them in response to feedback, or adjust its strategy over time. Automatically generated questions have been proposed to avoid memorization [32], but these bring their own issues, such as variable difficulty and occasional invalidity [18, 33].\n\nTo address this, we propose shifting the evaluation paradigm: from static, outcome- based tests toward dynamic, process- aware environments. We identify strategic games as a particularly well- suited testbed for this purpose. Games provide closed, rule- based environments with clear feedback signals, bounded resources, and interpretable decision traces. Their structure allows us to directly observe and quantify multi- step reasoning behaviors—without requiring human annotations or handcrafted evaluation rubrics.\n\nIn this work, we introduce AdvGameBench, a process- based evaluation framework that embeds LLMs in interactive, resource- constrained strategy games. Rather than judging success solely by win rates, our framework traces how models form plans, revise them when needed, and operate under strict resource budgets. We define a set of core evaluation dimensions—planning, revision, and resource- constrained decision making—and propose concrete metrics that capture each of them.\n\nTo support broad and interpretable analysis, AdvGameBench spans three classic game genres—tower defense, auto battler, and turn- based combat—each chosen to expose different cognitive and strategic demands. The framework logs full model outputs and action traces, enabling detailed inspection of decision quality, revision behavior, and adherence to constraints.\n\nOur key contributions are:\n\n- A formalization of reasoning process dimensions: planning, revision, and resource-constrained decision making.- A game-based evaluation framework that instantiates these dimensions using closed, interpretable, and reproducible environments.- A suite of evaluation metrics that measure not only whether models succeed, but how they reason through the task.\n\n# 2 Related work\n\nLLMs in Gaming Applications. LLMs have rapidly evolved and demonstrated significant capabilities across various complex tasks, including gaming scenarios[22][28][12][19][15]. Early studies mainly investigated their performance in text- based adventure games. For example, Tsai et al. [24] examined the capabilities of ChatGPT within interactive fiction. Subsequent research expanded to strategic and multi- agent scenarios. Notably, Akata et al. [1] explored repeated two- player interactions such as the Prisoner's Dilemma, highlighting the models' strengths in cooperative scenarios and coordination challenges.\n\nRecent attention has increasingly shifted toward multiplayer and complex card games. Yim et al. [31] studied Guandan, a sophisticated Chinese card game characterized by imperfect information and team cooperation. Their research demonstrated that prompting LLMs with Theory of Mind- like strategies significantly improved collaborative performance, but also revealed critical gaps in managing long- horizon states. Similarly, Hu et al. [13] proposed GameArena, a benchmark designed to evaluate fine- grained reasoning skills of LLMs through specialized interactive games.\n\nExisting Benchmarks for LLM Evaluation Despite these advancements, current benchmarks rely predominantly on simplified textual or stylized environments. AppWorld [23], GTBench [9], GAMEBENCH [7], MINT [27], and AgentBench [16] illustrate established efforts focusing on puzzle, multi- turn interactions, or agent- oriented tasks. Furthermore, Yang et al. [29] provided benchmarks specifically for StarCraft II, showcasing sophisticated summarization techniques in strategic gaming contexts. Another research direction evaluates strategic reasoning using game- theoretic frameworks, demonstrating how sophisticated models like GPT- 4 [20] approximate human decisions, but often fail to achieve a true rational equilibrium in adversarial or coordination- focused scenarios [17, 10].\n\nMultimodal and embodied approaches have also emerged as significant subfields, exemplified by works such as Voyager in Minecraft [25] and evaluations of the use of the LLM tool [30]. However, these approaches primarily tackle open- world exploration or general- purpose tasks rather than structured competitive scenarios common in mainstream gaming genres like tower defense or auto battlers. In addition, they often require frequent API interactions or repeated prompts, raising practical cost and latency concerns [26, 5].\n\nIn contrast to previous benchmarks that rely on tool- calling or open- ended exploration, AdvGameBench evaluates LLMs within strategic, rule- based environments where decision- making processes are directly observable. The framework eliminates external dependencies, imposes explicit budget constraints, and embeds models in turn- based adversarial settings. This design enables systematic analysis of not only final outcomes but also intermediate behaviors.\n\n# 3 Method\n\n# 3.1 Multi model adversarial structure\n\nWe introduce a structured adversarial framework for evaluating LLMs' process- level reasoning behaviors- specifically, how models plan, revision, and resource- constrained decision making in rule- constrained environments.\n\nGame- based, closed- loop setting. Each evaluation match embeds two LLMs in a closed, deterministic game simulator governed by explicit rules and resource constraints. Models receive identical prompts and independently generate strategies. The simulator ex ecutes both strategies and returns a rule- verifiable win/loss outcome.\n\n![](images/f0c323ba74c82a713d330c1c21e2c7df967f2187eb1f6d15fcc593a3922a0309.jpg)  \nFigure 1: This figure illustrates the AdvGameBench evaluation pipeline. Three strategic game genres—tower defense, auto-battler, and turn-based combat—form the core environments for model evaluation. In each round, the model generates a strategy based on explicit rules; the simulator executes the strategy and returns an outcome; the model optionally revises its plan; and this process iterates over multiple rounds. These interactions yield behavioral trajectories from which process-level metrics are computed, including win rate, over-correction risk rate, correction success rate, and over-budget rate.\n\nRole alternation across diverse games. We construct three adversarial games—tower defense, auto- battler, and turn- based combat—each targeting a distinct reasoning capability. In every round, models alternate between attacker and defender roles, exposing both offensive and defensive strategy formation.\n\nFeedback- driven revision. After each round, models receive outcome- based feedback. They may optionally revise their strategy. These revision sequences are logged and scored using process- aware metrics including correction success rate, over- correction risk, and improvement slope.\n\nControl for asymmetry. To eliminate bias, we evaluate each model pair under both move orders. This ensures symmetry and isolates model- specific behaviors from structural advantages.\n\nAdversarial matrix evaluation. The complete setup yields a dense match matrix, covering all model pairs, roles, and move orders. This enables systematic comparison of revision dynamics, constraint adherence, and planning robustness under matched conditions.\n\nOriginal game reimplementations. All game environments are re- implemented with shifted design from popular games to avoid strategy leakage from popular games. This ensures that models cannot rely on memorized heuristics or latent familiarity with existing game patterns, preserving the objectivity of the evaluation. All these code will be public available.\n\n# 3.2Game suites: Tower Defense,Auto-battler, Turn-based\n\nTo evaluate how LLMs revise and adapt across varied reasoning contexts, we design three game environments that span distinct forms of strategic complexity. Each environment imposes different constraints and interaction patterns: Tower Defense emphasizes spatial planning under sequential threats, Battle Card requires resource allocation and composition under outcome uncertainty, and Turn- based Game tests decision consistency across multi- step attribute interactions. This diversity ensures that our evaluation covers a broad spectrum of process- level reasoning behaviors.\n\nTower Defense Game. In this environment, models alternate between attacker and defender roles. Defenders place units on an 11- column battlefield to block attackers advancing from the right. Attackers aim to reach the left boundary, while defenders strive to destroy all attackers. Success criteria and rule violations provide clear feedback for iterative strategy refinement (see A.1).\n\nBattle Card Game. Models control units with distinct attributes: attackers prioritize damage, defenders emphasize protection and recovery. Units engage in automated battles, with combat sequence determined by the number of units each side possesses. The side that eliminates all opposing units first wins, offering explicit outcome- based feedback for model improvement (see A.2).\n\nTurn- based Attribute Game. Each side controls three characters with assigned elemental attributes (Fire, Wood, Water, Earth, Light, Dark), featuring strategic interactions based on attribute strengths and weaknesses. Characters choose three skills within a budget constraint, cycling through them in combat. Duels continue until one side remains, clearly indicating the strategic effectiveness and compliance of each model's choices (see A.3).\n\n# 3.3Evaluation metrics\n\nTo evaluate LLMs beyond raw outcomes, we define a set of metrics tracing how models revise strategies, manage constraints, and adapt over time. We categorize our metrics into three groups:\n\nOutcome metric: measures overall performance. Revision behavior metrics: assess how models respond to failure. Constraint adherence metrics: quantify rule compliance under resource limits.\n\nWin Rate (WR). Win Rate measures the proportion of matches a model wins out of all played games, with rule violations resulting in immediate forfeiture. This metric captures the final outcome of the reasoning process and provides a baseline for comparison. It reflects how well a model integrates planning, revision, and constraint handling into an executable solution.\n\nOver- Correction Risk Rate (ORR). ORR captures how frequently a model reacts to negative feedback with a revised proposal. This metric targets a critical behavior: over- adjustment in response to failure signals. In practical settings, excessive self- editing can reduce decision stability and degrade coherence over long horizons. High ORR indicates a lack of strategic confidence or an overly reactive revision policy. The need to track this behavior is grounded in the observation that models can degrade their own solutions through unnecessary changes, even when initial plans are viable.\n\nCorrection Success Rate (CSR). CSR measures how often a revision leads to an improved result- either by eliminating a rule violation or by turning a loss into a win. This metric isolates the effectiveness of the model's internal feedback loop: can it not only detect failure but also recover from it? A model that frequently edits without reliably improving demonstrates superficial adaptivity rather than meaningful self- correction.\n\nImprovement Slope  $(\\beta)$  . Improvement Slope captures whether a model improves over repeated interactions in matched environments. This measures whether the model can adapt its planning based on prior failures against a fixed opponent type. Unlike static metrics,  $\\beta$  traces whether a model learns or degrades over time. A flat or negative slope suggests overfitting or myopic adjustment; a positive slope reflects effective cumulative reasoning.\n\nOver- Budget Rate (OBR). OBR measures how often a model generates proposals that exceed explicit resource constraints. This metric directly evaluates a model's ability to integrate symbolic or numerical limits into its reasoning process. Many LLMs can optimize performance under unconstrained conditions, but OBR reveals whether they can internalize hard boundaries and behave accordingly. This behavior is essential for real- world deployment, where compliance with external rules is not optional but required for safe execution.\n\nTogether, these metrics provide complementary views into different layers of model behavior: WR evaluates final success; ORR and CSR analyze revision dynamics;  $\\beta$  measures adaptation over time; and OBR enforces structural discipline. Further detailed metrics are discussed in Appendix B.\n\n# 4 Results\n\nWe evaluate 12 leading LLMs, including DeepSeek- R1/V3 [8], Qwen- Plus/Max [4], Claude- 3.5- Sonnet [3], ChatGPT- 4.1/4o/o3/o3- mini [20], Gemini- 2/2.5- Flash [2], and LLaMA- 3- 70B [11]. All models use the same decoding settings: temperature 0.3 and top-  $p$  1, allowing for controlled but non- deterministic generation [21].\n\nTo assess robustness, each model was tested against three diverse opponents: ChatGPT- 4o, Claude3.5- Sonnet, and DeepSeek- V3. This setup avoids evaluation bias caused by shared architectures or training data. In each round, models play against all opponents in turn- based games, with the platform logging win/loss results and correction behaviors for downstream analysis.\n\n# 4.1 Revision behavior: correction rate & success\n\nTable 1: Benchmark Metrics (WR  $=$  win rate, ORR  $=$  over-correction risk, CSR  $=$  correction success)  \n\n<table><tr><td rowspan=\"2\">Model</td><td colspan=\"3\">TDG</td><td colspan=\"3\">BCG</td><td colspan=\"3\">TAG</td><td colspan=\"3\">avg</td></tr><tr><td>WR</td><td>ORR</td><td>CSR</td><td>WR</td><td>ORR</td><td>CSR</td><td>WR</td><td>ORR</td><td>CSR</td><td>WR</td><td>ORR</td><td>CSR</td></tr><tr><td>ChatGPT-4.1</td><td>45.0</td><td>85.7</td><td>40.0</td><td>52.5</td><td>69.7</td><td>65.2</td><td>57.5</td><td>82.4</td><td>67.9</td><td>51.7</td><td>79.4</td><td>56.8</td></tr><tr><td>ChatGPT-4o</td><td>65.8</td><td>81.8</td><td>55.6</td><td>60.8</td><td>44.0</td><td>63.6</td><td>59.1</td><td>82.4</td><td>46.4</td><td>58.6</td><td>70.4</td><td>52.6</td></tr><tr><td>ChatGPT-o3</td><td>75.8</td><td>41.1</td><td>57.1</td><td>76.7</td><td>50.0</td><td>88.9</td><td>70.0</td><td>30.0</td><td>66.7</td><td>74.2</td><td>40.0</td><td>73.7</td></tr><tr><td>ChatGPT-o3-mini</td><td>63.3</td><td>25.9</td><td>57.1</td><td>74.2</td><td>31.6</td><td>100.0</td><td>86.7</td><td>9.0</td><td>100.0</td><td>74.7</td><td>24.5</td><td>78.6</td></tr><tr><td>Claude-3-5-Sonnet</td><td>56.7</td><td>89.3</td><td>56.0</td><td>45.8</td><td>70.0</td><td>64.3</td><td>55.0</td><td>76.9</td><td>65.0</td><td>52.5</td><td>77.7</td><td>61.6</td></tr><tr><td>DeepSeek-R1</td><td>70.8</td><td>53.6</td><td>80.0</td><td>49.2</td><td>32.2</td><td>40.0</td><td>80.0</td><td>83.3</td><td>70.0</td><td>66.7</td><td>48.4</td><td>63.3</td></tr><tr><td>DeepSeek-V3</td><td>43.3</td><td>84.6</td><td>45.5</td><td>23.3</td><td>75.5</td><td>24.3</td><td>56.7</td><td>75.0</td><td>38.1</td><td>41.1</td><td>78.4</td><td>35.2</td></tr><tr><td>Gemini-2-Flash</td><td>15.8</td><td>90.6</td><td>10.4</td><td>49.2</td><td>65.7</td><td>60.9</td><td>38.3</td><td>67.5</td><td>28.0</td><td>34.4</td><td>76.8</td><td>27.1</td></tr><tr><td>Gemini-2-5-Flash</td><td>60.0</td><td>40.0</td><td>60.0</td><td>59.0</td><td>79.2</td><td>68.4</td><td>58.1</td><td>76.2</td><td>56.3</td><td>62.5</td><td>65.7</td><td>63.0</td></tr><tr><td>LLaMA-3-70B</td><td>33.3</td><td>90.2</td><td>29.7</td><td>42.5</td><td>76.3</td><td>51.7</td><td>65.0</td><td>69.2</td><td>66.7</td><td>46.9</td><td>80.0</td><td>45.2</td></tr><tr><td>Qwen-Max</td><td>39.2</td><td>44.7</td><td>5.8</td><td>10.8</td><td>50.0</td><td>10.3</td><td>41.7</td><td>51.3</td><td>36.9</td><td>30.5</td><td>48.9</td><td>16.9</td></tr><tr><td>Qwen-Plus</td><td>19.2</td><td>78.4</td><td>20.0</td><td>16.7</td><td>81.5</td><td>13.6</td><td>40.8</td><td>86.1</td><td>45.2</td><td>25.6</td><td>81.6</td><td>24.3</td></tr></table>\n\nTable 1 shows the win rate, over- correction risk rate, and correction success rate for evaluated models.\n\nWin Rate. ChatGPT- o3- mini and ChatGPT- o3 achieved the highest win rates at  $74.7\\%$  and  $74.2\\%$  respectively, substantially outperforming all other models. These results suggest strong capabilities in planning and decision- making under adversarial conditions. In contrast, models such as the Qwen series and Gemini- 2- Flash exhibited significantly lower win rates, indicating weaker performance in high- pressure strategic settings.\n\nOver- correction Risk Score. This metric reflects a model's tendency to overreact to feedback through frequent revisions. Qwen- Plus, DeepSeek- V3, and Claude- 3- 5- Sonnet exhibited high Over- correction Risk Rates (ORR), suggesting an unstable decision- making process characterized by impulsive or excessive adjustments. In contrast, ChatGPT- o3- mini maintained a relatively low ORR of  $49.3\\%$  indicating a more disciplined and stable strategy that avoids unnecessary revisions unless a confident improvement is identified.\n\nCorrection Success Rate. This measures the effectiveness of the attempted revisions. ChatGPT- o3- mini achieved the highest success rate at  $78.6\\%$  indicating that most of its corrections were accurate. Conversely, Qwen- Max and Qwen- Plus had success rates around  $20\\%$  despite frequent corrections, reflecting a tendency toward uninformed or premature changes- what we refer to as \"blind correction.\"\n\nThese findings highlight an important distinction: frequent correction behavior does not necessarily imply improved performance. High- performing models engaged in fewer revisions, but these were more targeted and successful. In contrast, models that frequently attempted corrections without sufficient understanding failed to translate effort into meaningful gains. Effective revision thus requires not just responsiveness, but discernment in identifying when and how to intervene.\n\n# 4.2 Planning ability: Init-win & Improvement Slope\n\n4.2 Planning ability: Init- win & Improvement SlopeWe evaluate planning capabilities using two complementary metrics: initial win rate (init- win), which reflects first- round performance without feedback, and improvement slope, which measures a model's ability to enhance its strategy over time. Together, they capture a model's capacity to start strong and adapt through interaction. Figure 2 shows win rate trajectories across five rounds, while Figure 3 reports improvement slopes.\n\n![](images/a7999e47cc294e3780c322532ec2bf8b71e684d66427a08eafef48595214ae67.jpg)  \nFigure 2: Planning performance: slope vs. initial win rate.\n\n![](images/7cd6ae2015b867248c5d3383f07f43c1f8bd93c26bf5229b09c9cfecc4185096.jpg)  \nFigure 3: Win-rate trajectories across five rounds.\n\nDeepSeek- R1 achieves the highest init- win  $(75.0\\%)$  but declines over time, suggesting rigid strategy design. In contrast, ChatGPT- o3 and o3- mini start with lower win rates  $(58.3\\%)$  yet steadily improve, indicating flexible planning. Models like Gemini- 2.5- Flash and Claude- 3.5- Sonnet perform well initially but regress, likely due to static heuristics. Qwen models show little progress, pointing to weak feedback integration. Across families, only ChatGPT models consistently improve, reflecting stronger adaptation. These patterns show that robust planning requires not just strong openings, but the ability to refine strategies under pressure—a key dimension captured by process- level metrics like the improvement slope.\n\n# 4.3 Resource-constrained decision making\n\nFigure 4 reports the Over- Budget Ratio (OBR), which quantifies the proportion of turns in which a model exceeds the environment's resource constraints. While most models stay within budget in over  $80\\%$  of turns, the variation across models is notable. ChatGPT- o3 and ChatGPT- o3- mini maintain perfect budget adherence, never exceeding the allowed limits. In contrast, Qwen- Plus surpasses its budget in approximately half of its turns, and Qwen- Max records similarly high overuse (OBRs of 0.50 and 0.45, respectively). This pattern is strongly aligned with performance: the o3 series models not only exhibit the lowest OBRs but also achieve the highest win rates  $(74.7\\%$  and  $74.2\\%)$  , whereas the Qwen models, with the highest OBRs, perform worst in terms of win rate  $(30.5\\%)$  and  $25.6\\%$  -\n\nWe further find a strong negative correlation between OBR and win rate (Pearson  $\\mathrm{r} = - 0.95$ $\\mathrm{p< 0.001}$  ), indicating that effective resource management is closely tied to model success. High OBRs are often associated with reactive, post- hoc revisions- corrections made after poor initial decisions- - which typically fail to compensate for early mistakes. Conversely, models with low OBRs demonstrate more disciplined planning and efficient execution, avoiding costly errors in the first place. These results position OBR as a meaningful process- level indicator that goes beyond outcome accuracy, revealing how well models translate abstract constraints into concrete and consistent decision- making. Strong performers not only remain within budget but also allocate their resources strategically, contributing to higher correction success and overall coherence in behavior.\n\n![](images/d6721b6d9597759f08ce12b9f9d4acddb7769325e3522440306fcf64dc62f30c.jpg)  \nFigure 4: Over-Budget Ratio for Each Model\n\n# 4.4 Does revising more really help?\n\n![](images/28cd35790e04fdbe08442d3ccd1d6ac52a88e5513a9e1e24ae15930f059422a8.jpg)  \nFigure 5: Correlation analysis between over-correction risk rate (ORR) and four main metrics across models\n\nWe quantify a model's tendency to revise reactively using the over- correction risk rate (ORR)- the probability that a model submits a new strategy immediately after receiving explicit negative feedback. Figure5 presents the correlation between ORR and four process- level outcomes. We observe a moderate negative relationship between ORR and final win rate  $(r = - 0.47$ $p = 0.13)$  , suggesting that models which revise more frequently tend to achieve lower overall success. Similarly, ORR correlates negatively with improvement slope  $(r = - 0.34$ $p = 0.28)$  , indicating that frequent edits do not accelerate strategic refinement. In terms of budget use, models with higher ORR values are more likely to exceed resource constraints (OBR;  $r = +0.43$ $p = 0.17$  ), and also show lower correction success rates  $(r = - 0.34$ $p = 0.28)$  , implying that high- frequency revision may undermine the quality of attempted corrections.\n\nAlthough none of these effects reach conventional thresholds for statistical significance due to the limited sample size  $n = 12$  ), the consistency in directional trends is notable. Across all four measures, models with high over- correction risk tend to perform worse: they are less efficient, less successful overall, and less disciplined in their resource usage. In contrast, top- performing models such as CHATGPT- 03- MINT pair a low ORR with high correction success and zero budget violations. These results highlight a key insight: precision in revision- not frequency- is the hallmark of effective strategy adjustment.\n\n# 4.5 Role symmetry and first-move bias\n\n![](images/67c122380be38c1564d3be9f5c28fd798a7b65a03dc0c4f87db402bfbbafa268.jpg)  \nFigure 6: First-mover advantage (FMA) across three behavioral dimensions.\n\nWe use First- Mover Advantage (FMA) to examine how model performance differs when initiating an action versus responding to a prior move. We analyze this effect across three dimensions: win rate, over- correction risk rate, and correction success rate. As shown in Figure 6a, most models exhibit relatively minor differences in win rate between first- and second- mover roles, with FMA values generally within five percentage points. This suggests limited systematic advantage based on turn order for overall success. However, several models deviate from this trend. Gemini- 2- Flash (FMA = +13.2%) performs substantially better when acting first, while ChatGPT- 4o (FMA = - 21.7%) and Qwen- Max (FMA = - 16.7%) exhibit the opposite pattern, achieving higher win rates when playing second. These results suggest that certain models are more sensitive to the structural asymmetries introduced by move order.\n\nStronger patterns emerge when examining correction behavior. In Figure 6b and Figure 6c, we observe that most models show a clear preference for initiating rather than responding. For example, ChatGPT- 4o and ChatGPT- 4.1 demonstrate significantly higher over- correction risk rates when acting first  $\\mathrm{(FMA = +14.8\\%)}$  and  $+13.8\\%$  , respectively). Similarly, first- mover performance gains are evident in correction success rates for Gemini- 2.5- Flash  $(+21.2\\%)$  Gemini- 2- Flash  $(+12.5\\%)$  ,and ChatGPT- 4.1  $(+19.9\\%)$  . These findings underscore the importance of accounting for role asymmetry in evaluation setups. Our dual- first configuration helps mitigate first- mover bias, offering a more balanced and interpretable view of model behavior under asymmetric game dynamics.\n\n# 4.6 Holistic comparison via radar chart\n\nTo synthesize model performance across reasoning dimensions, we constructed a radar chart visualizing five normalized metrics: win rate (WR), correction success rate (CSR), improvement slope, 1- over- correction risk rate (ORR), and 1- over- budget rate (OBR). All metrics were scaled to a common range, with inversions applied where necessary so that higher values consistently indicate better performance. This unified view enables a comparative assessment of both outcome and process quality across models.\n\n![](images/3e1fb5c2b1e2948981fcff75ef5efc84ccdfe7fdf60fa5d0cce2ecaeb3af004a.jpg)  \nFigure 7: Model performance metrics\n\nChatGPT- o3- and o3- mini form the largest radar areas, reflecting strong, consistent performance across all dimensions. They pair high win rates with effective corrections, stable improvement, and disciplined resource use, indicating well- integrated reasoning. In contrast, models like Qwen- Plus and Qwen- Max show sharp imbalances, marked by frequent but ineffective revisions and frequent budget violations. Gemini models perform moderately in CSR and planning but are similarly constrained by high correction risk or poor budget control. These patterns highlight that top performance requires balance across planning, revision, and constraint adherence—not just isolated strength. Larger radar areas correspond to more robust reasoning pipelines, reinforcing that process quality is essential to understanding model competence.\n\n# 4.7 Model-Specific Strengths and Underlying Mechanisms\n\nOur evaluation shows that different LLMs exhibit distinct process- level strengths, often reflecting differences in architecture and alignment. Models from the ChatGPT family—especially o3 and o3- mini—achieve consistently high win rates while maintaining disciplined correction behavior and strict budget adherence. This pattern suggests a stable internal revision mechanism, likely shaped by reinforcement learning with human feedback (RLHF) and conservative fine- tuning objectives that prioritize reliability over exploration. In contrast, models such as Qwen- Plus and DeepSeek- V3 revise frequently but achieve low correction success and often exceed resource limits. These behaviors point to reactive decision- making and overly eager feedback incorporation, which can destabilize planning over time. We refer to this pattern as “over- correction,” where excessive responsiveness leads to fragmented strategies and reduced overall performance.\n\nOther models, including Claude- 3.5- Sonnet and Gemini- 2.5- Flash, show more balanced profiles across metrics. While they do not dominate any single dimension, they perform moderately well in planning, correction, and resource management. This may reflect broader instruction- tuning or multitask training that encourages general adaptability without specializing in any one skill. Taken together, these differences underscore that LLM capabilities are shaped by design trade- offs: between caution and flexibility, local reactivity and global coherence. Our process- level metrics—particularly ORR and improvement slope—help reveal these trade- offs, offering a more nuanced view of model behavior than outcome- based evaluations alone. They also provide actionable insights into how alignment strategies and decoding preferences influence long- horizon reasoning, suggesting concrete directions for model development and benchmarking.\n\n# 5 Discussion\n\nProcess- rather- than- outcome evaluation. AdvGameBench purposefully shifts the evaluation lens from what an LLM answers to how it arrives there. By embedding models in three rule- bound strategy games, we can observe- and score- their behaviour along the three dimensions defined in Method section (see Method): planning (initial strategy quality and improvement slope), revision (correction rate and success), and resource- constrained decision making (budget adherence).\n\nEmpirical studies. Our study of twelve production- scale LLMs across 4 752 adversarial rounds yields three consistent findings:\n\n1. Integrated skill trumps single metrics. Models that balance the three dimensions-notably CHATGPT-O3-MINI with a  $74.7\\%$  win rate,  $78.6\\%$  correction-success rate, and positive improvement slope of  $+0.0413$  outperform models that excel in only one aspect. \n2. \"Spray-and-pray\" revision is counter-productive. QwEN-PLUS issues corrections in  $81.6\\%$  of error states yet wins only  $25.6\\%$  of gamer, and overspends in nearly half the turns. Across all systems, correction frequency and efficacy are negatively correlated (Pearson  $r = -0.51$ $p = 0.093)$  , indicating that calibrated self-editing matters more than sheer persistence. \n3. Budget fidelity is a leading indicator of success. The two models that never violated resource limits (CHATGPT-O3 and CHATGPT-O3-MINI) also posted the highest win rates, whereas both Qwen variants combine the largest over-budget ratios with the poorest outcomes.\n\nHallucation. In our tower defense experiments, all defensive units were consistently referred to as soldiers. However, several models frequently generated the term peashooter, which was never introduced in the task instructions. A review of the interaction logs reveals that this phenomenon does not stem from a reasoning failure, but rather from prior associations learned during pretraining- - specifically, the frequent co- occurrence of \"tower defense\" and the game Plants vs. Zombies in web- scale corpora. This leads models to default to familiar terminology, even when it conflicts with the defined rules of the environment. Such behavior undermines the validity of the benchmark, effectively turning the evaluation into a test of memorized correlations rather than genuine planning or constraint adaptation. To eliminate this form of memory bias, we redesigned the game environment to neutralize lexical cues and ensure that performance reflects models' ability to engage with novel rules and dynamic constraints, rather than recalling pretraining artifacts.\n\nLimitations. AdvGameBench currently (i) covers three turn- based genres but no real- time or cooperative play, (ii) logs unit- level actions yet does not attribute win contributions to individual decisions, and (iii) relies on synthetic opponents, which- - although diversified- - cannot fully mirror human play styles. These choices were deliberate to keep the study controlled and reproducible, but they constrain external validity.\n\n# 6 Conclusion\n\nStatic accuracy benchmarks have become an insufficient proxy for real- world robustness. Deployment- ready systems must also plan soundly, revise judiciously, and respect resource constraints to function effectively in practical environments. AdvGameBench meets this need by turning strategic gameplay into an open, extensible laboratory in which those process- level traits can be systematically quantified, monitored, and improved over time.\n\nBy exposing the entire decision trace- from initial plan through budgeted actions and selfcorrections- the benchmark reveals failure modes that outcome- only tests often conceal. These fine- grained signals enable not only diagnostic analysis of model behavior but also principled design of training objectives that reward disciplined, context- sensitive reasoning under pressure. They also help evaluate whether models can maintain stability across repeated trials, even in adversarial or resource- limited conditions. AdvGameBench supports controlled ablations, adversarial setups, and resource perturbations, making it a flexible platform for probing model resilience.\n\nUltimately, we see AdvGameBench as one step toward a broader shift in LLM evaluation: away from asking only \"Did the model answer correctly?\" and toward asking \"How did the model reason, adapt, and stay within bounds while answering?\" Such process- aware scrutiny is essential for building language models that are not only accurate but also reliable, accountable, and aligned with real- world deployment demands.\n\n# References\n\n[1] Akata, E., Schulz, L., Coda- Forno, J., Oh, S. J., Bethge, M., and Schulz, E. (2023). Playing repeated games with large language models. In arXiv preprint arXiv:2305.16867v1.\n\n[2] Anil, R., Borgeaud, S., Alayrac, J.- B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., Millican, K., Silver, D., Johnson, M., Antonoglou, I., Schrittwieser, J., Glaese, A., Chen, J., Pitler, E., Lillicrap, T., Lazaridou, A., Firat, C., Molloy, J., Isard, M., Barham, P. R., Hennigan, T., Lee, B., Viola, F., Reynolds, M., Xu, Y., Doherty, R., Collins, E., Meyer, C., Rutherford, E., Moreira, E., Ayoub, K., Goel, M., Krawczyk, J., Du, C., Chi, E., Cheng, H.- T., Ni, E., Shah, P., Kane, P., Chan, B., Faruqui, M., Severyn, A., Lin, H., Li, Y., Cheng, Y., Ittycheriah, A., Mahdieh, M., Chen, M., Sun, P., Tran, D., Bagri, S., Lakshminarayanan, B., Liu, J., Orban, A., Gira, F., Zhou, H., Song, X., Boffy, A., Ganapathy, H., Zheng, S., Choe, H., Weisz, Á., Zhu, T., Lu, Y., Gopal, S., Kahn, J., Kula, M., Pitman, J., Shah, R., Taropa, E., Al Merey, M., Baeuml, M., Chen, Z., El Shafey, L., Zhang, Y., Sercinoglu, O., Tucker, G., Piqueras, E., Krikun, M., Barr, I., Savinov, N., Danelhelka, I., Roelofs, B., White, A., Andreassen, A., von Glehn, T., Yagati, L., Kazemi, M., Gonzalez, L., Khalman, M., Sygnowski, J., Frechette, A., Smith, C., Culp, L., Prolev, L., Luan, Y., Chen, X., et al. (2025). Gemini: A Family of Highly Capable Multimodal Models. In arXiv preprint arXiv:2312.11805v5. Version v1 submitted on 19 Dec 2023, v5 (this version) revised 9 May 2025.\n\n[3] Anthropic (2024). The claude 3 model family: Opus, Sonnet, Haiku. Technical report, Anthropic. Model Card.\n\n[4] Bai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., Hui, B., Ji, L., Li, M., Lin, J., Lin, R., Liu, D., Liu, G., Lu, C., Lu, K., Ma, J., Men, R., Ren, X., Ren, X., Tan, C., Tan, S., Tu, J., Wang, P., Wang, S., Wang, W., Wu, S., Xu, B., Xu, J., Yang, A., Yang, H., Yang, J., Yang, S., Yao, Y., Yu, B., Yuan, H., Yuan, Z., Zhang, J., Zhang, X., Zhang, Y., Zhang, Z., Zhou, C., Zhou, J., Zhou, X., and Zhu, T. (2023). QWEN TECHNICAL REPORT. In arXiv preprint arXiv:2309.16609v1.\n\n[5] Chiang, W.- L., Zheng, L., Sheng, Y., Angelopoulos, A. N., Li, T., Li, D., Zhu, B., Zhang, H., Jordan, M. I., Gonzalez, J. E., and Stoica, I. (2024). Chatbot arena: An open platform for evaluating LLMs by human preference. In arXiv preprint arXiv:2403.04132v1.\n\n[6] Cobb, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. (2021). Training verifiers to solve math word problems. In arXiv preprint arXiv:2110.14168v2. Version v1 submitted on 27 Oct 2021, v2 (this version) revised 18 Nov 2021.\n\n[7] Costarelli, A., Allen, M., Hauksson, R., Sodunke, G., Hariharan, S., Cheng, C., Li, W., Clymer, J., and Yadav, A. (2024). GAMEBENCH: Evaluating strategic reasoning abilities of Ilm agents. In arXiv preprint arXiv:2406.06613v2.\n\n[8] DeepSeek- AI, Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., and et al. (2024). DeepSeek- V3 Technical Report. In arXiv preprint arXiv:2412.19437.\n\n[9] Duan, J., Zhang, R., Diffenderfer, J., Kailkhura, B., Sun, L., Stengel- Eskin, E., Bansal, M., Chen, T., and Xu, K. (2024). GTBENCH: Uncovering the strategic reasoning limitations of LLMs via game- theoretic evaluations. In arXiv preprint arXiv:2402.12348v2.\n\n[10] Fan, C., Chen, J., Jin, Y., and He, H. (2023). Can large language models serve as rational players in game theory? a systematic analysis. In arXiv preprint arXiv:2312.05488v2.\n\n[11] Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al- Dahle, A., Letman, A., Mathur, A., Schelten, A., Vaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra, A., Sravankumar, A., Korenev, A., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A., Gregerson, A., Spataru, A., Roziere, B., Biron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C., Bi, C., Marra, C., McConnell, C., Keller, C., Touret, C., Wu, C., Wong, C., Ferrer, C. C., Nikolaidis, C., Allonsius, D., Song, D., Pintz, D., Livshorn, D., Wyatt, D., Esiobu, D., Choudhary, D., Mahajan, D., Garcia- Olano, D., Perino, D., Hupkes, D., Lakomkin, E., AlBadawy, E., Lobanova, E., Dinan, E., Smith, E. M., Radenovic, F., Guzmán, F., Zhang, F., Synnaeve, G., Lee, G., Anderson, G. L.,\n\nThattai, G., Nail, G., Mialon, G., Pang, G., Cucurell, G., Nguyen, H., Korevaar, H., Xu, H., Touvron, H., Zarov, I., Ibarra, I. A., Kloumann, I., Misra, I., Evtimov, I., Zhang, J., Copet, J., Lee, J., Geffert, J., Vranes, J., Park, J., Mahadeokar, J., Shah, J., van der Linde, J., Billock, J., Hong, J., Lee, J., Fu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton, J., Spisak, J., Park, J., Rocca, J., Johnstun, J., Saxe, J., Jia, J., et al. (2024). The Llama 3 Herd of Models. In arXiv preprint arXiv:2407.21783v3. Version v1 submitted on 31 Jul 2024, v3 (this version) revised 23 Nov 2024.\n\n[12] Gupta, A. (2023). Are chatgpt and gpt- 4 good poker players? — a pre- flop analysis. In arXiv preprint arXiv:2308.12466v2. [13] Hu, L., Li, Q., Xie, A., Jiang, N., Stoica, I., Jin, H., and Zhang, H. (2025). GAMEARENA: Evaluating LLM reasoning through live computer games. In arXiv preprint arXiv:2412.06394v5. [14] Huang, J. and Chang, K. C.- C. (2023). Towards reasoning in large language models: A survey. In arXiv preprint arXiv:2212.10403v2. [15] Light, J. and et al. (2023). Avalonbench: Evaluating llms playing the game of avalon. arXiv preprint arXiv:2310.05036. [16] Liu, Y., Li, Z., Liu, P., Xie, Y., Wu, B., Zhang, Y., Wang, S., Yu, Y., Zhao, J., Lu, Z., Gao, Y., Qiao, Y., Fan, W., Ye, Y., Liang, S., and Zhao, Y. (2023). AgentBench: Evaluating LLMs as agents. In arXiv preprint arXiv:2308.03688. [17] Lore, N. and Heydari, B. (2023). Strategic behavior of large language models: Game structure vs. contextual framing. In arXiv preprint arXiv:2309.05898v1. [18] Minderer, M., Djolonga, J., Romijnders, R., Hubis, F., Zhai, X., Houlsby, N., Tran, D., and Lucic, M. (2021). Revisiting the calibration of modern neural networks. In arXiv preprint arXiv:2106.07998v2. Appeared in: 35th Conference on Neural Information Processing Systems (NeurIPS 2021). Version v1 submitted on 15 Jun 2021, v2 (this version) revised 26 Oct 2021. [19] Nannukul, N. and Wongkamjan, W. (2024). What if red can talk? dynamic dialogue generation using large language models. In arXiv preprint arXiv:2407.20382v1. [20] OpenAI (2024). GPT- 4 technical report. In arXiv preprint arXiv:2303.08774v6. [21] Renze, M. and Guven, E. (2024). The effect of sampling temperature on problem solving in large language models. In arXiv preprint arXiv:2402.05201v3. [22] Sudhakaran, S., Gonzalez- Duque, M., Freiberger, M., Glanois, C., Najarro, E., and Risi, S. (2023). MarioGPT: Open- ended Text2Level generation through large language models. In arXiv preprint arXiv:2302.05981v3. [23] Trivedi, H., Khot, T., Hartmann, M., Manku, R., Dong, V., Li, E., Gupta, S., Sabharwal, A., and Balasubramanian, N. (2024). AppWorld: A controllable world of apps and people for benchmarking interactive coding agents. In arXiv preprint arXiv:2407.18901v1. [24] Tsai, C. F., Zhou, X., Liu, S. S., Li, J., Mei, H., and Yu, M. (2023). Can large language models play text games well? current state- of- the- art and open questions. In arXiv preprint arXiv:2304.02868v1. [25] Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., and Anandkumar, A. (2023a). VOYAGER: An open- ended embodied agent with large language models. In arXiv preprint arXiv:2305.16291v2. [26] Wang, S., Long, Z., Fan, Z., Wei, Z., and Huang, X. (2024). Benchmark self- evolving: A multi- agent framework for dynamic LLM evaluation. In arXiv preprint arXiv:2402.11443v1. [27] Wang, Y., Yu, D., Dong, L., Bao, F. S., Wang, X., Wang, D., Yu, Z., Li, L., and Zhou, H. (2023b). MINT: Evaluating LLMs in multi- turn interaction with tools and language feedback. In arXiv preprint arXiv:2310.06825. [28] Xu, Y., Wang, S., Li, P., and et al. (2023). Exploring large language models for communication games: An empirical study on werewolf. arXiv preprint arXiv:2309.04658.\n\n[29] Yang, Z., Li, H., Chen, Y., Tian, W., Ren, Y., Su, H., Zhu, J., and Sun, L. (2023a). Large language models play StarCraft II: Benchmarks and a chain of summarization approach. In arXiv preprint arXiv:2310.11432. [30] Yang, Z., Li, L., Wang, J., Lin, K., Azarnasab, E., Ahmed, F., Liu, Z., Liu, C., Zeng, M., and Wang, L. (2023b). MM- REACT: Prompting ChatGPT for multimodal reasoning and action. In arXiv preprint arXiv:2303.11381v1. [31] Yim, Y., Chan, C., Shi, T., Deng, Z., Fan, W., Zheng, T., and Song, Y. (2024). Evaluating and enhancing LLMs agent based on theory of mind in Guandan: A multiplayer cooperative game under imperfect information. In arXiv preprint arXiv:2408.02559v1. [32] Yu, X., Cheng, H., Liu, X., Roth, D., and Gao, J. (2024). ReEval: Automatic hallucination evaluation for retrieval- augmented large language models via transferable adversarial attacks. In arXiv preprint arXiv:2310.10190v2. Version v1 submitted on 19 Oct 2023, v2 (this version) revised 31 May 2024. [33] Zhang, H., Da, J., Lee, D., Robinson, V., Wu, C., Song, W., Zhao, T., Raja, P., Zhuang, C., Slack, D., Lyu, Q., Hendryx, S., Kaplan, R., Lunati, M., and Yue, S. (2024a). A careful examination of large language model performance on grade school arithmetic. In arXiv preprint arXiv:2405.00212v4. Version v1 submitted on 1 May 2024, v4 (this version) revised 22 Nov 2024. Original v1 arXiv:2405.00212. [34] Zhang, Y., Mao, S., Ge, T., Wang, X., de Wynter, A., Xia, Y., Wu, W., Song, T., Lan, M., and Wei, F. (2024b). LLM as a mastermind: A survey of strategic reasoning with large language models. In arXiv preprint arXiv:2404.01230v1.\n\n# A Appendix\n\n# A.1 Tower defense game\n\n# A.1.1 Game rules\n\n1. Players can purchase characters and place them on the battlefield. The battlefield consists of 5 rows (corresponding to y-coordinates 0-4). The human side can place units in a designated area spanning 11 columns (corresponding to x-coordinates 0-10). \n2. Demons spawn from the right side of the battlefield (x-coordinates 11) and move left. Human units are placed on the left side of the battlefield, remain stationary, and attack approaching enemies. \n3. All units attack according to their attack interval, automatically attacking when their cooldown ends. Defending units fire bullets or activate skills to attack enemies. Invading units engage in melee attacks when they come into contact with defending units. \n4. Each grid cell can only contain one human unit at a time. Placing a new unit in an occupied cell is not allowed. \n5. When an attack hits, the target takes damage based on the attacker's power. If a unit's health drops to 0, it is eliminated and removed from the battlefield. \n6. If all enemies are eliminated, the player wins. If any enemy successfully reaches the left side of the battlefield, the player loses.\n\n# A.1.2 Human units\n\n<table><tr><td>Unit</td><td>Attributes</td></tr><tr><td>HandgunSoldier</td><td>Health: 3, Shooting interval: 1000ms, Cost: 100, Damage per shot: 1, No special abilities.</td></tr><tr><td>RifleSoldier</td><td>Health: 3, Shooting interval: 500ms, Cost: 200, Damage per shot: 1, No special abilities.</td></tr><tr><td>MachineGunSoldier</td><td>Health: 3, Shooting interval: 250ms, Cost: 400, Damage per shot: 1, No special abilities.</td></tr></table>\n\n<table><tr><td>ShieldSoldier</td><td>Health: 15, Cost: 50, Only for defense, no attack capabilities.</td></tr><tr><td>EnhancedShieldSoldier</td><td>Health: 30, Cost: 100, Only for defense, no attack capabilities and Bouncing Demon cannot jump over.</td></tr><tr><td>FlamethrowerSoldier</td><td>Health: 2, Cost: 200, Shooting interval: 1000ms, Damage per shot: 1, Deals an additional 1 damage every 1000ms.</td></tr><tr><td>IceSoldier</td><td>Health: 2, Shooting interval: 1000ms, Cost: 200, Damage per shot: 1, Reduces enemy speed by half.</td></tr><tr><td>AntiAirSoldier</td><td>Health: 2, Shooting interval: 1000ms, Cost: 175, Damage per shot: 1, Can attack airborne units.</td></tr><tr><td>Bomb</td><td>Health: 50, Detonation time: 500ms, Cost: 200, Explosion range: 3×3, Damage per explosion: 30, Destroyed after detonation.</td></tr><tr><td>LinearExplosion</td><td>Health: 50, Detonation time: 500ms, Cost: 200, Explosion range: the entire row, Damage per explosion: 30, Destroyed after detonation.</td></tr><tr><td>MagneticSoldier</td><td>Health: 2, Shooting interval: 2000ms, Cost: 100, Damage per shot: 0, Releases a magnetic pulse that disables the defensive abilities of ShieldDemon and MachineDemon.</td></tr><tr><td>LightMage</td><td>Health: 2, Damage per shot: 0, Cost: 150, No attack capabilities, Changes the attributes of bullets in the same row, converting their damage type to light.</td></tr><tr><td>RocketLauncherSoldier</td><td>Health: 2, Shooting interval: 1000ms, Damage per shot: 2, Cost: 600, Launches rockets, dealing damage to enemies within one grid.</td></tr></table>\n\n# A.1.3 Demon units\n\nNote: A speed of 2 requires 14 seconds to travel from spawn to the last human grid.\n\n<table><tr><td>Unit</td><td>Attributes</td></tr><tr><td>NormalDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 100, Damage per attack: 1, No special abilities.</td></tr><tr><td>GreatDemon</td><td>Health: 20, Speed: 2, Attack interval: 1000ms, Cost: 175, Damage per attack: 1, Higher health.</td></tr><tr><td>DemonKing</td><td>Health: 100, Speed: 2, Attack interval: 1000ms, Cost: 800, Damage per attack: 5.</td></tr><tr><td>SpeedyDemon</td><td>Health: 10, Speed: 4, Attack interval: 1000ms, Cost: 150, Damage per attack: 1, Moves faster.</td></tr><tr><td>ShieldDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 175, Damage per attack: 1, Takes 70% less damage from normal attacks.</td></tr><tr><td>MachineDemon</td><td>Health: 20, Speed: 2 (increases to 3 when activated), Attack interval: 1000ms, Cost: 250, Damage per attack: 3, Reduced damage due to mechanical body.</td></tr><tr><td>BouncingDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 150, Damage per attack: 1, Can jump over certain units except for the EnhancedShieldSoldier.</td></tr><tr><td>ShieldBreakerDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 150, Damage per attack: 1 (×5 against shield units).</td></tr><tr><td>FireDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 150, Damage per attack: 1, Immune to fire damage.</td></tr><tr><td>FrostDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 150, Damage per attack: 1, Immune to ice damage and unaffected by slow effects.</td></tr></table>\n\n<table><tr><td>FlyingDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 200, Damage per attack: 1, Only affected by anti-air attacks and can pass through human units directly.</td></tr><tr><td>ShadowDemon</td><td>Health: 10, Speed: 2, Attack interval: 1000ms, Cost: 300, Damage per attack: 1, Can cast dark magic, making same-row allies immune to non-light damage.</td></tr><tr><td>SummoningDemon</td><td>Health: 10, Speed: 1, Attack interval: 1000ms, Cost: 300, Damage per attack: 1, Summons a Normal Demon to the left grid every 5000ms.</td></tr></table>\n\n# A.2 Battle card game\n\n# A.2.1 Game rules\n\n1. At the start of the game, players can purchase all desired characters at once, up to a maximum of 7 characters. Gold characters cost three times as much as bronze characters, but their stats (attack, health, numerical skill effects, etc.) are twice as high. Non-numerical skills are not affected by this multiplier.  \n2. Initiative Determination: The side with more characters attacks first. If both sides have the same number of characters, the invader attacks first.  \n3. Elemental Advantage: Certain elements have an advantage over others, granting a bonus in combat (Fire > Nature, Nature > Water, Water > Earth, Earth > Fire).  \n4. Battle Process: Both sides will attack based on their respective target_priority (target priority). However, if there are Taunt minions on the opponent's side, attackers must prioritize attacking them. The attack order follows a left-to-right sequence. The first minion in the invaders or defenders fist (as defined in the JSON file) will attack first, depending on which side has the initiative. After that, the first minion from the opposing side attacks. Then, the second minion from the attacking side follows, then the second minion from the opposing side, and so on in an alternating pattern. If a minion's health reaches zero, it is eliminated. The battle continues with both sides attacking in turns until one side is completely wiped out, resulting in victory for the other side.  \n5. If all characters on one side are eliminated, the other side wins.  \n6. If both sides are eliminated simultaneously in the same attack resolution, the Invader wins.\n\n5. If all characters on one side are eliminated, the other side wins.\n\n6. If both sides are eliminated simultaneously in the same attack resolution, the Invader wins.\n\n# A.2.2 Invader units\n\n<table><tr><td>Unit</td><td>Attributes</td></tr><tr><td>FireLizard</td><td>Attack: 2, Health: 2, Cost: 1, Ability: Deals 2 damage to the enemy that killed it upon death.</td></tr><tr><td>WaterElemental</td><td>Attack: 2, Health: 2, Cost: 1, Ability: Gains +1 Attack when attacking.</td></tr><tr><td>PoisonFrog</td><td>Attack: 1, Health: 1, Cost: 2, Ability: Instantly destroys any minion it damages.</td></tr><tr><td>MoltenBound</td><td>Attack: 3, Health: 1, Cost: 2, Ability: Deals 1 damage to all enemies upon death.</td></tr><tr><td>BattleFenry</td><td>Attack: 7, Health: 4, Cost: 2, Ability: Each attack reduces its Attack by 4.</td></tr><tr><td>BanditLeader</td><td>Attack: 8, Health: 3, Cost: 3, Ability: Any excess damage from an attack carries over to the next target.</td></tr><tr><td>LavaGolem</td><td>Attack: 1, Health: 8, Cost: 3, Ability: Forces enemies to attack this minion first, Burns the attacker for 3 damage per turn when hit.</td></tr><tr><td>TideGuardian</td><td>Attack: 4, Health: 2, Cost: 3, Ability: Absorbs the first source of damage taken (divine shield), Attacks twice each turn.</td></tr><tr><td>TideLord</td><td>Attack: 4, Health: 9, Cost: 5, Ability: Doubles its Attack when taking damage.</td></tr></table>\n\n<table><tr><td>Phoenix</td><td>Attack: 5, Health: 5, Cost: 5, Ability: Deals damage equal to its Attack to the target and its adjacent enemies, Revives with full Health after being defeated once per game.</td></tr><tr><td>ShadowOverlord</td><td>Attack: 4, Health: 4, Cost: 5, Ability: Summons a Slow Skeleton (3/1) upon death.</td></tr></table>\n\n# A.2.3 Defender units\n\n<table><tr><td>Unit</td><td>Attributes</td></tr><tr><td>Sapling</td><td>Attack: 2, Health: 2, Cost: 1, Ability: Gains +1 Health when attacking.</td></tr><tr><td>Rock Beetle</td><td>Attack: 1, Health: 5, Cost: 1, Ability: Forces enemies to attack this minion before others.</td></tr><tr><td>ForestSeer</td><td>Attack: 2, Health: 2, Cost: 2, Ability: At the start of the game, grants +1 Attack and +2 Health to all Nature Allies.</td></tr><tr><td>Stone Warrior</td><td>Attack: 2, Health: 5, Cost: 2, Ability: Forces enemies to attack this minion before others. Summons a Rock Beetle upon death.</td></tr><tr><td>Elite Soldier</td><td>Attack: 1, Health: 1, Cost: 2, Ability: At the start of the game, grants Divine Shield to adjacent minions and +1 Attack.</td></tr><tr><td>Paladin</td><td>Attack: 3, Health: 6, Cost: 3, Ability: Has Divine Shield; gains +2 Attack whenever a friendly minion loses its Divine Shield.</td></tr><tr><td>BlackRock</td><td>Attack: 5, Health: 1, Cost: 3, Ability: At the start of the game, gains +3 Health for each friendly minion.</td></tr><tr><td>Vine Protector</td><td>Attack: 5, Health: 4, Cost: 3, Ability: Upon death, restores 2 Health to all friendly minions.</td></tr><tr><td>King</td><td>Attack: 3, Health: 10, Cost: 5, Ability: Summons a 2/2 Soldier with Divine Shield whenever it attacks (if there is an open space).</td></tr><tr><td>MountainGiant</td><td>Attack: 4, Health: 9, Cost: 5, Ability: Forces enemies to attack this minion first, Reduces the attack of the attacker by 2 when hit.</td></tr><tr><td>AncientTreant</td><td>Attack: 4, Health: 4, Cost: 5, Ability: At the start of the game, grants +3 Attack and +3 Health to all allied minions.</td></tr></table>\n\n# A.3 Turn-based attribute game\n\n# A.3.1 Game rules\n\n1. This game is a turn-based character battle game divided into two factions: Invader and Defender. Each faction consists of three characters. The Invader faction includes Fire, Water, and Dark elements, while the Defender faction includes Wood, Earth, and Light elements. Characters appear and act in the order they are listed in the data. \n2. Combat proceeds in rounds. In each round, the three Invader characters act first in order, followed by the three Defender characters. The sequence then repeats in the next round. \n3. Each character has three skills that are used in a preset, looping sequence. On each turn, a character uses the next skill in their list and continues cycling through them in order. \n4. The game features an elemental effectiveness system: Fire beats Wood, Wood beats Earth, Earth beats Water, and Water beats Fire (1.2× damage when effective, 0.8× when resisted). Light and Dark counter each other with 1.5× damage. All other combinations deal the standard 1.0× damage. \n5. If all characters on one side are eliminated, the other side wins.\n\n# A.3.2 Invader skills\n\n<table><tr><td>Skill Name</td><td>Description</td></tr><tr><td>Fire Skills</td><td></td></tr><tr><td>flame_splash</td><td>Deals 12 damage and applies Burning for 2 rounds (1 layer, 5 damage per round). Cost: 1</td></tr><tr><td>residual_warmth</td><td>Increases the damage of the next fire-based skill by 30% for 1 round. Cost: 1</td></tr><tr><td>burst_flame_bomb</td><td>Deals 25 base damage, plus 3 additional damage for each Burning layer on the target. Cost: 2</td></tr><tr><td>flame_whirlwind</td><td>Applies 4 layers of Burning to the target, lasting 2 rounds. Each layer deals 5 damage per round. Cost: 2</td></tr><tr><td>magma_eruption</td><td>Deals 40 base damage, plus 5 extra damage per Burning layer. Removes all Burning after the attack. Cost: 3</td></tr><tr><td>hell_curtain</td><td>Deals 35 damage and grants a shield that reflects 30 melee damage, lasting 2 rounds (1 layer). Cost: 3</td></tr><tr><td>Water Skills</td><td></td></tr><tr><td>stream_pierce</td><td>Deals 10 damage and grants 1 permanent layer of Tidal Surge. Cost: 1</td></tr><tr><td>water_bARRIER</td><td>Grants a 5-point shield for 3 rounds and increases Tidal Surge by 1 layer. Cost: 1</td></tr><tr><td>whirlpool_strangle</td><td>Deals 20 base damage, plus 4 additional damage per Tidal Surge layer. Cost: 2</td></tr><tr><td>ice_branched</td><td>Deals 15 damage and causes the target to take 50% more damage next turn (1 round). Cost: 2</td></tr><tr><td>tsunami_ending</td><td>Deals 30 base damage, plus 5 additional damage per Tidal Surge layer. Removes all Tidal Surge after the attack. Cost: 3</td></tr><tr><td>abyss_resonance</td><td>Deals 3 damage per Tidal Surge layer and grants a shield worth 6 per layer, lasting 3 rounds. Cost: 3</td></tr><tr><td>Dark Skills</td><td></td></tr><tr><td>shadow_claw</td><td>Deals 14 damage and heals the user for 30% of the damage dealt (rounded down). Cost: 1</td></tr><tr><td>fear_whisper</td><td>Reduces the target&#x27;s damage taken by 10% for 3 rounds (1 layer). Cost: 1</td></tr><tr><td>soul_siphon</td><td>Deals 25 damage. If the target&#x27;s HP is below 50%, deals an extra 15 damage. Cost: 2</td></tr><tr><td>night_ambush</td><td>Deals 20 damage and causes the target to take 20% more damage next turn (1 round). Cost: 2</td></tr><tr><td>final_announcement</td><td>Deals 45 base damage, plus 5 extra damage for every 10% HP the target has lost. Cost: 3</td></tr><tr><td>void_assimilation</td><td>Sacrifices 20% of current HP to deal penetration damage equal to twice the HP sacrificed. Cost: 3</td></tr></table>\n\n# A.3.3 Defender skills\n\n<table><tr><td>Skill Name</td><td>Description</td></tr><tr><td>Wood Skills</td><td></td></tr><tr><td>bud_healing</td><td>Grants Bud Healing for 3 rounds, restoring 6 HP per round. Cost: 1</td></tr><tr><td>parasitic_seed</td><td>Applies Parasitic Seed for 3 rounds, immediately deals 10 damage. The target takes 5 counter damage each time they attack. Cost: 1</td></tr><tr><td>life_totem</td><td>Restores 25 HP and grants Life Totem for 3 rounds, increasing healing received by 10%. Cost: 2</td></tr><tr><td>natural_purification</td><td>Removes negative statuses from the user and deals 30 damage to the target. Cost: 2</td></tr><tr><td>forest_reincarnation</td><td>Restores 60 HP. If it exceeds max HP, the excess is converted into a shield (50% of excess HP) for 3 rounds. Also deals 20 damage to an enemy. Cost: 3</td></tr></table>\n\n<table><tr><td colspan=\"2\">Earth Skills</td></tr><tr><td>rock armor</td><td>Grants 12 shield for 3 rounds and reflects 5 melee damage while the shield is active. Cost: 1</td></tr><tr><td>earth_shock</td><td>Deals 20 damage. Cost: 1</td></tr><tr><td>granite_barrier</td><td>Grants Granite Barrier for 3 rounds, decreasing damage by 40%. Cost: 2</td></tr><tr><td>quicksand Trap</td><td>Applies Quicksand Trap for 3 rounds. The target&#x27;s next 3 damage are delayed by 20% and each trigger deals 10 damage. Cost: 2</td></tr><tr><td>earth_pulse</td><td>Grants shield based on HP lost (8 shield per 10% HP lost), lasting permanently. Cost: 3</td></tr><tr><td>core_rebound</td><td>Deals 80% of stored damage to the target. Clears stored damage after use. Cost: 3</td></tr><tr><td colspan=\"2\">Light Skills</td></tr><tr><td>holy_glimmer</td><td>Removes a negative status (if any) and restores 8 HP to the user. Also deals 8 light damage to an enemy. Cost: 1</td></tr><tr><td>faith Emblem</td><td>Grants Faith Emblem for 1 round. The next damage taken is reduced by 20% and converted into healing. When triggered, deals 10 damage to the attacker. Cost: 1</td></tr><tr><td>divine_link</td><td>Grants Divine Link for 1 round. The next damage taken is reflected back to the attacker. Cost: 2</td></tr><tr><td>luminous_dispel</td><td>Removes one buff from the target (if any) and applies a debuff for 2 rounds that reduces their attack by 15%. Cost: 2</td></tr><tr><td>angelic_sanctuary</td><td>Grants Angelic Sanctuary for 3 rounds, reducing all incoming damage by 30 points. Cost: 3</td></tr><tr><td>divine_sword</td><td>Deals 20 damage and grants a buff that increases the next skill&#x27;s damage by 20. Cost: 3</td></tr></table>\n\n# B Additional evaluation metrics\n\nThis section details supplementary metrics used to provide a more granular understanding of LLM behavior in strategic game environments, complementing the core metrics presented in Section 3.4.\n\n# B.1 Rule violation Rate (RVR)\n\nThis metric measures how often a model's initial strategy proposal fails to adhere to the game's explicit rules, particularly budget constraints. Let  $M_{i}$  denote model  $i$  Let  $T_{i}$  be the total number of initial strategy proposals made by model  $M_{i}$  across all games and rounds where it provides an initial strategy. For each initial strategy proposal  $S_{i,t}^{(0)}$  (where  $t$  indexes these proposals,  $t\\in \\{1,\\ldots ,T_i\\})$  let  $V(S_{i,t}^{(0)})$  be an indicator function, such that  $V(S_{i,t}^{(0)}) = 1$  if the strategy  $S_{i,t}^{(0)}$  violates any game rule (including budget constraints), and  $V(S_{i,t}^{(0)}) = 0$  otherwise. The Rule Violation Rate for model  $M_{i}$  is:\n\n$$\n\\mathrm{RVR}_i = \\frac{\\sum_{t = 1}^{T_i}V(S_{i,t}^{(0)})}{T_i} \\tag{1}\n$$\n\nA lower RVR indicates better adherence to explicit constraints during initial planning phases.\n\n# B.2 Constructive Rate (CnstrR)\n\nThis metric assesses whether a correction attempt, following negative feedback, leads to an objectively improved game state, even if it doesn't immediately result in a win or full rule compliance. Let  $E_{i,g,k}$  be the event that negative feedback is received for strategy  $S_{i,g,k}$  (model  $i$ , game instance  $g$ ,  $k$ - th strategy in that game instance). Let  $A_{i,g,k + 1}$  be the event that model  $M_{i}$  proposes a new strategy  $S_{i,g,k + 1}$  in response. Let  $\\Phi (S)$  be a game- specific state evaluation function where higher values indicate a more advantageous position for the model (e.g., based on remaining unit health/cost difference, reduced enemy threat, or other heuristic measures of game state quality). A correction\n\n$S_{i,g,k + 1}$  is considered constructive if  $\\Phi (S_{i,g,k + 1}) > \\Phi (S_{i,g,k})$ . The Constructive Rate for model  $M_{i}$  is:\n\n$$\n\\mathrm{CnstrR}_i = \\frac{\\sum_{g = 1}^{G_i}\\sum_{k = 0}^{K_{i,g} - 1}\\mathbb{I}(E_{i,g,k}\\wedge A_{i,g,k + 1}\\wedge(\\Phi(S_{i,g,k + 1}) > \\Phi(S_{i,g,k})))}{\\sum_{g = 1}^{G_i}\\sum_{k = 0}^{K_{i,g} - 1}\\mathbb{I}(E_{i,g,k}\\wedge A_{i,g,k + 1}) + \\epsilon} \\tag{2}\n$$\n\nwhere  $G_{i}$  is the total number of game instances involving model  $M_{i}$  where corrections are possible,  $K_{i,g}$  is the number of strategies proposed by model  $M_{i}$  in game instance  $g,\\mathbb{I}(\\cdot)$  is the indicator function, and  $\\epsilon$  is a small constant to prevent division by zero. This captures the tendency for revisions to make incremental, positive progress. Calculating  $\\Phi (S)$  requires domain- specific heuristics tailored to each game environment.\n\n# B.3 Multi-aspect Strategic Similarity Ratio  $(S_{\\mathrm{MASR}})$\n\nThis metric assesses the similarity between a corrected strategy  $S^{(k + 1)}$  and the preceding strategy  $S^{(k)}$  by considering multiple facets: structural, semantic, and functional similarity. For a given model  $M_{i}$ , let  $S_{i,g,k}$  be the  $k$ - th strategy in game instance  $g$ . Let  $\\mathrm{Sim}_{\\mathrm{struct}}(S^{\\prime},S)$ ,  $\\mathrm{Sim}_{\\mathrm{sem}}(S^{\\prime},S)$ , and  $\\mathrm{Sim}_{\\mathrm{func}}(S^{\\prime},S)$  be normalized similarity scores in  $[0,1]$  for these aspects:\n\n- Structural Similarity  $(\\mathrm{Sim}_{\\mathrm{struct}})$ : Measures overlap in concrete elements (e.g., unit types, positions, configurations). This can be quantified using metrics like the Jaccard index on sets of chosen units/actions, or a normalized graph edit distance if strategies are represented as graphs  $G(S)$ . For instance,  $\\mathrm{Sim}_{\\mathrm{struct}}(S^{\\prime},S) = 1 - \\frac{\\mathrm{GED}(G(S^{\\prime}),G(S^{\\prime})}{\\mathrm{max} \\cdot \\mathrm{GED}}$ , where GED is graph edit distance.- Semantic Similarity  $(\\mathrm{Sim}_{\\mathrm{sem}})$ : Measures similarity in the underlying strategic intent or concept, often derived from embeddings of textual descriptions or structured representations of the strategy. If  $\\mathbf{e}(S)$  is an embedding vector for strategy  $S$ , then  $\\mathrm{Sim}_{\\mathrm{sem}}(S^{\\prime},S) = \\max (0,\\text{cosine similarity} (\\mathbf{e}(S^{\\prime}),\\mathbf{e}(S)))$ .- Functional Similarity  $(\\mathrm{Sim}_{\\mathrm{func}})$ : Measures overlap in the intended strategic functions or roles fulfilled by the strategy components (e.g., defensive formations, offensive pushes, resource gathering focus). If  $\\mathcal{F}(S)$  is the set of strategic functions embodied by strategy  $S$ , then  $\\mathrm{Sim}_{\\mathrm{func}}(S^{\\prime},S) = \\frac{|\\mathcal{F}(S^{\\prime})\\cap\\mathcal{F}(S)|}{|\\mathcal{F}(S^{\\prime})\\cup\\mathcal{F}(S)| + \\epsilon^{\\prime}}$ , where  $\\epsilon^{\\prime}$  prevents division by zero for empty sets.\n\nThe multi- aspect similarity ratio for a specific correction from  $S_{i,g,k}$  to  $S_{i,g,k + 1}$  is a weighted combination:\n\n$$\n\\mathcal{S}_{\\mathrm{MASR}}(S_{i,g,k + 1},S_{i,g,k}) = \\sum_{j = 1}^{N_{\\mathrm{aspecs}}}\\theta_j\\cdot \\mathrm{Sim}_{\\mathrm{aspect}_j}(S_{i,g,k + 1},S_{i,g,k}) \\tag{3}\n$$\n\nwhere  $N_{\\mathrm{aspecs}}$  is the number of similarity aspects (e.g., 3 for structural, semantic, functional), and  $\\theta_{j}$  are weights such that  $\\sum_{j = 1}^{N_{\\mathrm{aspecs}}}\\theta_{j} = 1$  and  $\\theta_{j}\\geq 0$ . The average  $\\bar{S}_{\\mathrm{MASR}}(i)$  for model  $M_{i}$  is calculated over all valid correction steps:\n\n$$\n\\mathcal{S}_{\\mathrm{MASR}}(i) = \\frac{\\sum_{g = 1}^{G_i}\\sum_{k = 0}^{K_{i,g} - 1}\\mathbb{I}(E_{i,g,k}\\wedge A_{i,g,k + 1})\\cdot\\mathcal{S}_{\\mathrm{MASR}}(S_{i,g,k + 1},S_{i,g,k})}{\\sum_{g = 1}^{G_i}\\sum_{k = 0}^{K_{i,g} - 1}\\mathbb{I}(E_{i,g,k}\\wedge A_{i,g,k + 1}) + \\epsilon} \\tag{4}\n$$\n\nThis metric quantifies the degree of strategic preservation or alteration during revisions. A high  $\\bar{S}_{\\mathrm{MASR}}(i)$  indicates a tendency towards conservative revision, while a low value suggests more aggressive or radical strategy changes.\n\n# B.4 First-Mover Advantage (FMA)\n\nFirst- Mover Advantage (FMA) quantifies the performance difference for a model when it acts first (initiates the interaction or round) versus when it acts second (responds to the opponent's initial move). This can be calculated for various performance metrics  $X$ , such as Win Rate (WR), Over- correction Risk Rate (ORR), or Correction Success Rate (CSR). Let  $M_{i}$  be the model under evaluation. Let  $\\mathcal{G}_{i,\\mathrm{first}}$  be the set of game instances where model  $M_{i}$  moved first, and  $\\mathcal{G}_{i,\\mathrm{second}}$  be the set of game instances where model  $M_{i}$  moved second. Let  $N_{i,\\mathrm{first}}(X) = |\\mathcal{G}_{i,\\mathrm{first}}|$  and  $N_{i,\\mathrm{second}}(X) = |\\mathcal{G}_{i,\\mathrm{second}}|$  be the respective counts of such game instances for which metric  $X$  is applicable. Let  $X_{i,m}$  be the\n\nvalue of metric  $X$  observed for model  $M_{i}$  in a specific game instance  $m$ . The average performance for model  $M_{i}$  on metric  $X$  when moving first is:\n\n$$\n\\bar{X}_{i,\\mathrm{first}} = \\frac{1}{N_{i,\\mathrm{first}}(X) + \\epsilon}\\sum_{m\\in \\mathcal{G}_{i,\\mathrm{first}}}X_{i,m} \\tag{5}\n$$\n\nSimilarly, the average performance for model  $M_{i}$  on metric  $X$  when moving second is:\n\n$$\n\\bar{X}_{i,\\mathrm{second}} = \\frac{1}{N_{i,\\mathrm{second}}(X) + \\epsilon}\\sum_{m\\in \\mathcal{G}_{i,\\mathrm{second}}}X_{i,m} \\tag{6}\n$$\n\nwhere  $\\epsilon$  is a small positive constant to prevent division by zero if a model never plays in one of the roles or if the metric is not applicable in those instances. The First- Mover Advantage for metric  $X$  and model  $M_{i}$  is then defined as the difference:\n\n$$\n\\mathrm{FMA}_X(i) = X_{i,\\mathrm{first}} - \\bar{X}_{i,\\mathrm{second}} \\tag{7}\n$$\n\nA positive  $\\mathrm{FMA}_X(i)$  indicates that model  $M_{i}$  performs better on metric  $X$  when it has the first- move advantage. Conversely, a negative value suggests better performance when moving second. The magnitude of  $\\mathrm{FMA}_X(i)$  indicates the strength of this turn- order bias.",
  "backend": "vlm-transformers"
}